{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TZuanazzi/Liver_Segmentation_NN/blob/main/CustomLoss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nV7r8fuC_pu",
        "outputId": "0349b042-36cb-4f90-e15f-33ffce998a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.3.post0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.15.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.3.post0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.4.0.post0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: TorchAudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from TorchAudio) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->TorchAudio) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->TorchAudio) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->TorchAudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->TorchAudio) (1.3.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Collecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (0.18.0+cu121)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (4.66.4)\n",
            "Collecting requests~=2.25.1 (from torchattacks)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.25.2)\n",
            "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.1->torchattacks) (12.5.40)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.2->torchattacks) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Installing collected packages: urllib3, idna, chardet, requests, torchattacks\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.9.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.14.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.40 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.19\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install tqdm\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install TorchAudio\n",
        "!pip install Cython\n",
        "!pip install torchattacks\n",
        "!pip install opencv-python\n",
        "!pip install PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEKMw_e1DPWt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class DresdenDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        basename = os.path.basename(image_dir)\n",
        "        self.label_dir = os.path.join((os.path.dirname(image_dir)),\n",
        "                                      basename, 'merged')\n",
        "        self.transform = transform\n",
        "        self.image_names = [filename for filename in os.listdir(image_dir) if filename.startswith(\"image\")]\n",
        "        self.label_names = [filename for filename in os.listdir(image_dir) if filename.startswith(\"mask\")]\n",
        "\n",
        "        # Sort the image and label names based on the numeric part extracted from filenames\n",
        "        self.image_names.sort(key=lambda x: int(x[5:7]))  # Extract the two-digit number from \"imageXX.png\"\n",
        "        self.label_names.sort(key=lambda x: int(x[4:6]))  # Extract the two-digit number from \"maskXX.png\"\n",
        "\n",
        "        # print(\"image_names:\", self.image_names)\n",
        "        # print(\"label:\", self.label_names)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def classes(self):\n",
        "        return torch.Tensor([0,1])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        image = np.array(Image.open(os.path.join(self.image_dir, self.image_names[idx])).convert('RGB'))\n",
        "        label1 = np.array(Image.open(os.path.join(self.image_dir, self.label_names[idx])).convert('RGB'))\n",
        "        # to use just three conditions, we create another label with np.zeros\n",
        "        label = np.zeros(np.shape(label1), np.uint8)[:,:,0:2]\n",
        "        label[:,:,0][label1[:,:,0]>125] = 1\n",
        "        label[:,:,1][label1[:,:,0]<125] = 1\n",
        "\n",
        "        dictionary = {'image0': image, 'image1': label}\n",
        "\n",
        "        if self.transform is not None:\n",
        "            dictionary = self.transform(dictionary)\n",
        "\n",
        "        return dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXVPEOTtDRfF",
        "outputId": "dfdaba93-1c93-46de-96c3-b97669a57953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# import time\n",
        "\n",
        "# Since nn.Sequential does not handle multiple inputs, create mySequential to\n",
        "# handle it, inhiriting from nn.Sequential\n",
        "class mySequential(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        for module in self._modules.values():\n",
        "            if type(inputs) == tuple:\n",
        "                inputs = module(*inputs)\n",
        "            else:\n",
        "                inputs = module(inputs)\n",
        "        return inputs\n",
        "\n",
        "\n",
        "class block_standard(nn.Module):\n",
        "    #defining block expansion\n",
        "    expansion: int = 1\n",
        "    # To devide the 'out_channels' by 2 in the standard, we create this variab.\n",
        "    out_multiply: int = 2\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1, up=False):\n",
        "\n",
        "        super(block_standard, self).__init__()\n",
        "\n",
        "        self.up = up\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        if self.up:\n",
        "            self.conv1 = nn.ConvTranspose2d(in_channels, out_channels,\n",
        "                                            kernel_size=stride, stride=stride)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                                   stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "\n",
        "    def forward(self, x, long_skip=None):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        if (self.identity_downsample is not None):\n",
        "            identity = self.identity_downsample(identity)\n",
        "        # if long_skip==None: print('long skip none')\n",
        "        if long_skip is not None:\n",
        "            x = torch.cat((x, long_skip), dim=1)\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "\n",
        "        del identity\n",
        "\n",
        "        return x, long_skip\n",
        "\n",
        "\n",
        "class block_bottleneck(nn.Module):\n",
        "    # defining block expansion\n",
        "    expansion: int = 4\n",
        "    # To devide the 'out_channels' by 2 in the standard, we create this variab.\n",
        "    out_multiply: int = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, identity_scale=None, stride=1, up=False):\n",
        "\n",
        "        super(block_bottleneck, self).__init__()\n",
        "\n",
        "        self.up = up\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        if self.up:\n",
        "            self.expansion = 2\n",
        "        else:\n",
        "            self.expansion = 4\n",
        "\n",
        "        if self.up:\n",
        "            self.conv1 = nn.ConvTranspose2d(in_channels, out_channels,\n",
        "                                            kernel_size=stride, stride=stride)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                                   stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        if self.up:\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                                   stride=1, padding=1)\n",
        "        else:\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                                   stride=stride, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion,\n",
        "                               kernel_size=1, stride=1, padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_scale = identity_scale\n",
        "\n",
        "    def forward(self, x, long_skip=None):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_scale is not None:\n",
        "            identity = self.identity_scale(identity)\n",
        "        # if long_skip==None: print('long skip none')\n",
        "        if long_skip is not None:\n",
        "            x = torch.cat((x, long_skip), dim=1)\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "\n",
        "        del identity\n",
        "\n",
        "        return x, long_skip\n",
        "\n",
        "class UResNet(nn.Module): # [3, 4, 6, 3]\n",
        "\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "\n",
        "        super(UResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        # First Convolutions\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7,stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.long_skip = []\n",
        "\n",
        "        # ResNet Layers  [3, 4, 6, 3]\n",
        "        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
        "        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
        "        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
        "\n",
        "        # ResNet Layers\n",
        "        self.layer5 = self._make_layer(block, layers[3], out_channels=512, stride=2, up=True)\n",
        "        self.layer6 = self._make_layer(block, layers[2], out_channels=256, stride=2, up=True)\n",
        "        self.layer7 = self._make_layer(block, layers[1], out_channels=128, stride=2, up=True)\n",
        "        self.layer8 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "\n",
        "        # Last Convolutions\n",
        "        self.conv_last1 = nn.ConvTranspose2d(self.in_channels, 64,kernel_size=2, stride=2, padding=0)\n",
        "        self.conv_last2 = nn.ConvTranspose2d(64*2, num_classes,kernel_size=2, stride=2, padding=0)\n",
        "        self.bn2 = nn.BatchNorm2d(num_classes)\n",
        "        self.Softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        self.long_skip = [0, 0, 0, 0]\n",
        "        self.long_skip[0] = x\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x, temp = self.layer1(x, None)\n",
        "        self.long_skip[1] = x\n",
        "        x, temp = self.layer2(x, None)\n",
        "        self.long_skip[2] = x\n",
        "        x, temp = self.layer3(x, None)\n",
        "        self.long_skip[3] = x\n",
        "        x, temp = self.layer4(x, None)\n",
        "\n",
        "        self.long_skip = self.long_skip[::-1]\n",
        "\n",
        "        x, temp = self.layer5(x, self.long_skip[0])\n",
        "        x, temp = self.layer6(x, self.long_skip[1])\n",
        "        x, temp = self.layer7(x, self.long_skip[2])\n",
        "        x, temp = self.layer8(x, None)\n",
        "        x = self.conv_last1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.cat((x, self.long_skip[3]), dim=1)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv_last2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.Softmax(x)\n",
        "\n",
        "        del self.long_skip, temp\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks,\n",
        "                         out_channels, stride, up=False):\n",
        "        identity_scale = None\n",
        "        layers = []\n",
        "\n",
        "        if up==False:\n",
        "            if stride != 1 or self.in_channels != out_channels*block.expansion:\n",
        "                identity_scale = mySequential(nn.Conv2d(self.in_channels,\n",
        "                                                        out_channels*block.expansion,\n",
        "                                                        kernel_size=1,\n",
        "                                                        stride=stride),\n",
        "                                              nn.BatchNorm2d(out_channels*block.expansion))\n",
        "\n",
        "            layers.append(block(self.in_channels, out_channels,\n",
        "                                identity_scale, stride))\n",
        "            self.in_channels = out_channels*block.expansion\n",
        "\n",
        "            for i in range(num_residual_blocks-1):\n",
        "                layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        else:\n",
        "            if stride != 1 or self.in_channels != out_channels*block.expansion:\n",
        "                identity_scale = mySequential(nn.ConvTranspose2d(self.in_channels,\n",
        "                                                                 out_channels*block.expansion,\n",
        "                                                                 kernel_size=stride,\n",
        "                                                                 stride=stride),\n",
        "                                              nn.BatchNorm2d(out_channels*block.expansion))\n",
        "            # This is to devide the 'out_channels' by 2 in the standard block\n",
        "            # if you see, the output channels is really half of the value in\n",
        "            # this block.\n",
        "            out_channels = int(out_channels/block.out_multiply)\n",
        "            layers.append(block(self.in_channels, out_channels,\n",
        "                                identity_scale, stride, up=True))\n",
        "\n",
        "            if stride==1 and up==True:\n",
        "                self.in_channels = out_channels*2\n",
        "            elif block.expansion == 1 and up==True:\n",
        "                self.in_channels = out_channels*2\n",
        "            else:\n",
        "                self.in_channels = out_channels*4\n",
        "\n",
        "            for i in range(num_residual_blocks-1):\n",
        "                layers.append(block(self.in_channels, out_channels, up=True))\n",
        "\n",
        "        return mySequential(*layers)\n",
        "\n",
        "def UResNet18(in_channels=3, num_classes=1000):\n",
        "    return UResNet(block_standard, [2, 2, 2, 2], in_channels, num_classes)\n",
        "\n",
        "def UResNet34(in_channels=3, num_classes=1000):\n",
        "    return UResNet(block_standard, [3, 4, 6, 3], in_channels, num_classes)\n",
        "\n",
        "def UResNet50(in_channels=3, num_classes=1000):\n",
        "    return UResNet(block_bottleneck, [3, 4, 6, 3], in_channels, num_classes)\n",
        "\n",
        "def UResNet101(in_channels=3, num_classes=1000):\n",
        "    return UResNet(block_bottleneck, [3, 4, 23, 3], in_channels, num_classes)\n",
        "\n",
        "def UResNet152(in_channels=3, num_classes=1000):\n",
        "    return UResNet(block_bottleneck, [3, 8, 36, 3], in_channels, num_classes)\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = UResNet18()\n",
        "    # working sizes 224, 256, 288\n",
        "    x = torch.randn(2, 3, 224, 224)\n",
        "    if torch.cuda.is_available():\n",
        "        y = net(x).to('cuda')\n",
        "    else:\n",
        "        y = net(x)\n",
        "    print(y.shape)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test()\n",
        "\n",
        "# print('- Time taken:', time.time()-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWAj3YuwDSrd"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This file is used together with the 'train.py' file to help in the training and\n",
        "testing process with util functions.\n",
        "'''\n",
        "import torch\n",
        "#from dataset import DresdenDataset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.transforms.functional as tf\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from torchmetrics import Dice\n",
        "\n",
        "\n",
        "# The next functions are functional transforms, used to apply functions in a way\n",
        "# controled by the user. So we can apply, for example, in the data image and in\n",
        "# the label image (so it is called deterministic, because we can determine the\n",
        "# same transformation to be applied in more then one image). This is the unique\n",
        "# way to apply the same transformation to more then one different image in torch\n",
        "\n",
        "class ToTensor(object):\n",
        "    '''Function to transform a ndarray in a tensor\n",
        "\n",
        "    n: int (input)\n",
        "        number of non-mask images to convert to tensor (the rest will be\n",
        "        converted without scaling to [0.0,1.0])'''\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for i, image in enumerate(images):\n",
        "            if i < self.n:\n",
        "                images[image] = tf.to_tensor(images[image])\n",
        "            else:\n",
        "                images[image] = torch.from_numpy(images[image])\n",
        "                images[image] = torch.permute(images[image], (2,0,1))\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class Rotate(object):\n",
        "    '''Function to rotate an image, the input is a dictionary\n",
        "\n",
        "    images: 'dictionary' (input)\n",
        "        dictionary with images;\n",
        "    limit: 'list'\n",
        "        a list 'int' with smaller and larger angles to rotate (e.g. [0, 90]);\n",
        "    p: 'float'\n",
        "        probability to rotate;\n",
        "\n",
        "    dictionary: 'dictionary' (output)\n",
        "        dictionary with cropped images with keys 'image0', 'image1', etc.\n",
        "    '''\n",
        "    def __init__(self,**kwargs):\n",
        "        # 'limit' is a 'list' that defines the lower and upper angular limits\n",
        "        limit = kwargs.get('limit')\n",
        "        if not limit: limit = [0, 360]\n",
        "        self.limit = limit\n",
        "        # 'p' is 'float' the probability to happen a rotate\n",
        "        p = kwargs.get('p')\n",
        "        if not p: p = 0.5\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, images):\n",
        "        if random.random() > 1-self.p:\n",
        "            angle = random.randint(self.limit[0], self.limit[1])\n",
        "            for i, image in enumerate(images):\n",
        "                images[image] = tf.rotate(images[image], angle)\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class CenterCrop(object):\n",
        "    '''Function to center crop one or multiple images\n",
        "\n",
        "    size: 'list' (input)\n",
        "        input list with size (e.g. '[400,200]');\n",
        "    images: 'dictionary' (input) (output)\n",
        "        dictionary with images.\n",
        "    '''\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for image in images:\n",
        "            images[image] = tf.center_crop(images[image], self.size)\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class Resize(object):\n",
        "    '''Function to resize one or multiple images\n",
        "\n",
        "    size: 'list' (input)\n",
        "        input list with size (e.g. '[400,200]');\n",
        "    images: 'dictionary' (input) (output)\n",
        "        dictionary with images.\n",
        "    '''\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for image in images:\n",
        "            images[image] = tf.resize(images[image], self.size)\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class FlipHorizontal(object):\n",
        "    '''Horizontally flip images randomly\n",
        "\n",
        "    p: 'float' (input)\n",
        "        probability to flip (from 0.0 to 1.0).\n",
        "    '''\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, images):\n",
        "        if random.random() > 1-self.p:\n",
        "            for image in images:\n",
        "                images[image] = tf.hflip(images[image])\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class FlipVertical(object):\n",
        "    '''Vertically flip images randomly\n",
        "\n",
        "    p: 'float' (input)\n",
        "        probability to flip (from 0.0 to 1.0).\n",
        "    '''\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, images):\n",
        "        if random.random() > 1-self.p:\n",
        "            for image in images:\n",
        "                images[image] = tf.vflip(images[image])\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class Normalize(object):\n",
        "    '''Normalizing 'n' images of a given set of images\n",
        "\n",
        "    n: int (input)\n",
        "        number of images to normalize;\n",
        "    mean: list (input)\n",
        "        mean to normalize;\n",
        "    std: list (input)\n",
        "        stadard deviation to normalize.\n",
        "    '''\n",
        "    def __init__(self, n=1, mean=0.5, std=0.5):\n",
        "        self.n = n\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for i, image in enumerate(images):\n",
        "            if i < self.n:\n",
        "                images[image] = tf.normalize(images[image], self.mean, self.std)\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class Affine(object):\n",
        "    '''Affining images\n",
        "\n",
        "    size: list (input)\n",
        "        maximum higher and width to translate image (normally the image size);\n",
        "    scale: float (input)\n",
        "        scale to perform affine (between 0 and 1.0);\n",
        "    p: float (input)\n",
        "        probability to thange.'''\n",
        "    def __init__(self, size=[0,0], scale=0.5, p=0.5):\n",
        "        self.size = size\n",
        "        self.scale = scale\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, images):\n",
        "        if random.random() > 1-self.p:\n",
        "            angle = random.random()*self.scale*360\n",
        "            shear = random.random()*self.scale*360\n",
        "            translate = [i*random.random()*self.scale for i in self.size]\n",
        "            for image in images:\n",
        "                images[image] = tf.affine(images[image], angle=angle,\n",
        "                                         translate=translate, scale=1-self.scale,\n",
        "                                         shear=shear)\n",
        "        return images\n",
        "\n",
        "\n",
        "#%% Util Functions to be Used During Training or Testing\n",
        "\n",
        "# saving checkpoints\n",
        "def save_checkpoint(state, filename='my_checkpoint.pth.tar'):\n",
        "    print('\\n- Saving Checkpoint...')\n",
        "    torch.save(state, filename)\n",
        "\n",
        "# loading checkpoints\n",
        "def load_checkpoint(checkpoint, model, optimizer=None):\n",
        "    print('\\n- Loading Checkpoint...')\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    if optimizer:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "# getting loaders given directories and other informations\n",
        "def get_loaders(train_image_dir,\n",
        "                valid_percent,\n",
        "                test_percent,\n",
        "                batch_size,\n",
        "                image_height,\n",
        "                image_width,\n",
        "                num_workers=1,\n",
        "                pin_memory=True,\n",
        "                val_image_dir=None,\n",
        "                clip_valid=1.0,\n",
        "                clip_train=1.0):\n",
        "\n",
        "    # first, defining transformations to be applied in the train images to be loaded\n",
        "    transform_train_0 = Compose([ToTensor(n=1),\n",
        "                                 Resize(size=[image_height, image_width]),\n",
        "                                 FlipVertical(p=0.5),\n",
        "                                 FlipHorizontal(p=0.5),\n",
        "                                 # mean and std, obtained from Dresden Dataset\n",
        "                                 # for segmentation\n",
        "                                 Normalize(n=1, mean=[0.4338, 0.31936, 0.312387],\n",
        "                                           std=[0.1904, 0.15638, 0.15657])]\n",
        "#as funções feitas aqui foram feitas pelo marlon ,explicar no testo que essas biblitecas pode ser chamadas de function trasnforms, ele significa\n",
        "                                # não usar uma transformação do pytorchm, mas sim uma propria sua\n",
        "# essas trasnformações\n",
        "                                )\n",
        "    # defining the same, but for validation and testing images (can be different)\n",
        "    transform_valid_0 = Compose([ToTensor(n=1),\n",
        "                                 Resize(size=[image_height, image_width]),\n",
        "                                 FlipVertical(p=0.5),\n",
        "                                 FlipHorizontal(p=0.5),\n",
        "                                 # defining again if validation dataset is dif.\n",
        "                                 Normalize(n=1, mean=[0.4338, 0.31936, 0.312387],\n",
        "                                           std=[0.1904, 0.15638, 0.15657])]\n",
        "                                )\n",
        "\n",
        "    # second, defining the number of transformations per directory in\n",
        "    # 'train_image_dir' defines the data augmantation (1 for no augmentation\n",
        "    # and 5 for 5 times augmentation)\n",
        "    transformations_per_dataset = [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
        "                                   5, 5, 5, 5, 5, 5]\n",
        "\n",
        "    # third, reading the dataset in a as a 'torch.utils.data.Dataset' instance.\n",
        "    # it is only for images in 'train_image_dir[0]', further we will accounts\n",
        "    # for the rest of the directories\n",
        "    train_dataset = DresdenDataset(image_dir=train_image_dir[0],\n",
        "                                  transform=transform_train_0)\n",
        "    print(\"train_dataset:\",train_dataset)\n",
        "\n",
        "    # concatenate the other directories in 'train_image_dir[:]' in a larger\n",
        "    # 'torhc.utils.data.Dataset'. after we will concatenate more for augmentat.\n",
        "    for n in range(1, len(train_image_dir)):\n",
        "        dataset_train_temp = DresdenDataset(image_dir=train_image_dir[n],\n",
        "                                           transform=transform_train_0)\n",
        "        # to use 'train_dataset' here in right, we have to define it before\n",
        "        train_dataset = torch.utils.data.ConcatDataset([train_dataset,\n",
        "                                                        dataset_train_temp])\n",
        "\n",
        "    # using part of the training data as test dataset\n",
        "    test_dataset_size = int(test_percent*len(train_dataset))\n",
        "    rest_size = int((1-test_percent)*len(train_dataset))\n",
        "    if test_dataset_size+rest_size != len(train_dataset):\n",
        "        rest_size += 1\n",
        "    (test_dataset, _) = random_split(train_dataset, [test_dataset_size, rest_size],\n",
        "                                     generator=(torch.Generator().manual_seed(40)))\n",
        "\n",
        "    # defining the validation dataset, using part of the 'train_dataset', or\n",
        "    # using a specific dataset for validation, if 'val_image_dir' is not 'None'\n",
        "    if not val_image_dir:\n",
        "        valid_dataset_size = int(valid_percent*len(train_dataset))\n",
        "        train_dataset_size = int((1-valid_percent)*len(train_dataset))\n",
        "        # adding one to train_dataset_size if 'int' operation removed it\n",
        "        if valid_dataset_size+train_dataset_size != len(train_dataset):\n",
        "            train_dataset_size += 1\n",
        "        (train_dataset, valid_dataset) = random_split(train_dataset,\n",
        "                                         [train_dataset_size, valid_dataset_size],\n",
        "                                         generator=torch.Generator().manual_seed(20))\n",
        "    else:\n",
        "        valid_dataset = DresdenDataset(image_dir=val_image_dir[0],\n",
        "                                      transform=transform_valid_0)\n",
        "        for n in range(1, len(val_image_dir)):\n",
        "            dataset_val_temp = DresdenDataset(image_dir=val_image_dir[n],\n",
        "                                             transform=transform_valid_0)\n",
        "            valid_dataset = torch.utils.data.ConcatDataset([valid_dataset,\n",
        "                                                            dataset_val_temp])\n",
        "\n",
        "    # concatenating the augmented data, in case 'transf..._per_dataset' > 1\n",
        "    for n in range(0,len(train_image_dir)):\n",
        "        for m in range(1, transformations_per_dataset[n]):\n",
        "            # first we specify the transformation (depending on the 'm' value)\n",
        "            if m < 2:\n",
        "                transformation = Compose([ToTensor(n=1),\n",
        "                                          Rotate(limit=[(m-1)*72,m*72], p=1.0),\n",
        "                                          Resize(size=[image_height, image_width]),\n",
        "                                          FlipVertical(p=0.5),\n",
        "                                          FlipHorizontal(p=0.5),\n",
        "                                          # Mean and std, obtained from the dataset\n",
        "                                          Normalize(n=1, mean=[0.4338, 0.31936, 0.312387],\n",
        "                                                    std=[0.1904, 0.15638, 0.15657])]\n",
        "                                          )\n",
        "            else:\n",
        "                transformation = Compose([ToTensor(n=1),\n",
        "                                          Affine(size=[0.5*image_height, 0.5*image_width],\n",
        "                                                 scale=0.01*(m-1), p=0.5),\n",
        "                                          Rotate(limit=[(m-1)*72,m*72], p=1.0),\n",
        "                                          Resize(size=[image_height, image_width]),\n",
        "                                          FlipVertical(p=0.5),\n",
        "                                          FlipHorizontal(p=0.5),\n",
        "                                          # Mean and std, obtained from the dataset\n",
        "                                          Normalize(n=1, mean=[0.4338, 0.31936, 0.312387],\n",
        "                                                    std=[0.1904, 0.15638, 0.15657])]\n",
        "                                          )\n",
        "            # then we apply this transformation to read the dataset as 'torch.utils.data.Dataset'\n",
        "            dataset_train_temp = DresdenDataset(image_dir=train_image_dir[n],\n",
        "                                               transform=transformation)\n",
        "            train_dataset = torch.utils.data.ConcatDataset([train_dataset, dataset_train_temp])\n",
        "\n",
        "    # splitting the dataset, to deminish if 'clip_valid'<1 for fast testing\n",
        "    if clip_train < 1:\n",
        "        print('\\n- Splitting Training Dataset ',clip_train*100,'%')\n",
        "        train_mini = int(clip_train*len(train_dataset))\n",
        "        temp_mini = int((1-clip_train)*len(train_dataset))\n",
        "        if train_mini+temp_mini != len(train_dataset):\n",
        "            temp_mini += 1\n",
        "        (train_dataset, _) = random_split(train_dataset,[train_mini, temp_mini],\n",
        "                                          generator=torch.Generator().manual_seed(40))\n",
        "    if clip_valid < 1:\n",
        "        print('\\n- Splitting Validation Dataset ',clip_valid*100,'%')\n",
        "        valid_mini = int(clip_valid*len(valid_dataset))\n",
        "        temp_mini = int((1-clip_valid)*len(valid_dataset))\n",
        "        if valid_mini+temp_mini != len(valid_dataset):\n",
        "            temp_mini += 1\n",
        "        (valid_dataset, _) = random_split(valid_dataset,[valid_mini, temp_mini],\n",
        "                                          generator=torch.Generator().manual_seed(30))\n",
        "        (test_dataset, _) = random_split(test_dataset, [valid_mini, temp_mini],\n",
        "                                         generator=torch.Generator().manual_seed(50))\n",
        "\n",
        "    # obtaining dataloader from the datasets defined above\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "\n",
        "    return train_loader, test_loader, valid_loader\n",
        "\n",
        "# functino to check accuracy\n",
        "def check_accuracy(loader, model, loss_fn, device='cuda' if torch.cuda.is_available() else 'cpu', **kwargs):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    model.eval()\n",
        "    # if title is passed, use it before 'Check acc' and 'Got an accuracy...'\n",
        "    title = kwargs.get('title')\n",
        "    if title==None: title = ''\n",
        "    else: title = title+': '\n",
        "    # using tqdm.tqdm to show a progress bar\n",
        "    loop = tqdm(loader, desc=title+'Check acc')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for dictionary in loop:\n",
        "            image, label = dictionary\n",
        "            x, y = dictionary[image], dictionary[label]\n",
        "            x, y = x.to(device=device), y.to(device=device)\n",
        "            y = y.float()\n",
        "            pred = model(x)\n",
        "            y = tf.center_crop(y, pred.shape[2:])\n",
        "            pred = (pred > 0.5).float()\n",
        "            loss = loss_fn(pred, y)\n",
        "            num_correct += (pred == y).sum()\n",
        "            num_pixels += torch.numel(pred)\n",
        "            # next is to calculate dice-score\n",
        "            pred = pred.to(device='cpu').to(torch.int32)\n",
        "            y = y.to(device='cpu').to(torch.int32)\n",
        "            dice = Dice(ignore_index=0)\n",
        "            dice_score += dice(pred, y)\n",
        "            loop.set_postfix(acc=str(round(100*num_correct.item()/int(num_pixels),4)))\n",
        "            # deliting variables\n",
        "            loss_item = loss.item()\n",
        "            del loss, pred, x, y, image, label, dictionary\n",
        "    # deliting variables\n",
        "    num_correct_item = num_correct.item()\n",
        "    num_pixels = int(num_pixels)\n",
        "    dice_score_item = dice_score.item()\n",
        "    len_loader = len(loader)\n",
        "    del num_correct, dice_score, loader, loop\n",
        "\n",
        "    print('\\n'+title+f'Got an accuracy of {round(100*num_correct_item/int(num_pixels),4)}')\n",
        "\n",
        "    print('\\n'+title+f'Dice score: {round(100*dice_score_item/len_loader,4)}'+'\\n')\n",
        "    model.train()\n",
        "    return 100*num_correct_item/num_pixels, loss_item, 100*dice_score_item/len_loader\n",
        "\n",
        "# saving images (only if the output are images)\n",
        "def save_predictions_as_imgs(loader, model, folder='saved_images',\n",
        "                             device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "                             **kwargs):\n",
        "    # If image is grayscale, if yes, we have to turn into rgb to save\n",
        "    gray = kwargs.get('gray')\n",
        "    # With model in evaluation\n",
        "    model.eval()\n",
        "    for idx, (dictionary) in enumerate(loader):\n",
        "        image, label = dictionary\n",
        "        x, y = dictionary[image], dictionary[label]\n",
        "        x = x.to(device=device)\n",
        "        y = y.to(dtype=torch.float32)\n",
        "        y = y.to(device=device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(x)\n",
        "            y = tf.center_crop(y, pred.shape[2:])\n",
        "            pred = (pred > 0.5).float()\n",
        "        # If image is grayscale, transforming to 'rgb' (utils.save_image needs)\n",
        "        if gray:\n",
        "            pred = torch.cat([pred,pred,pred],1)\n",
        "            y = y.unsqueeze(1)\n",
        "            y = torch.cat([y,y,y],1)\n",
        "            y = y.float()\n",
        "            y = tf.center_crop(y, pred.shape[2:])\n",
        "        save_image(pred, f'{folder}/pred_{idx}.png')\n",
        "        save_image(y, f'{folder}/y_{idx}.png')\n",
        "\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AY2FpUFcPlMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48030e5-77cf-4912-ad83-881ba28897aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "11kmrXe5DUEN",
        "outputId": "ab34b16a-7687-4246-ce2c-9c57a2f50e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "train_dataset: <__main__.DresdenDataset object at 0x7c1e12c66a40>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Loading Checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCheck acc:   0%|          | 0/17 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Check acc: 100%|██████████| 17/17 [01:22<00:00,  4.84s/it, acc=80.7934]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Got an accuracy of 80.7934\n",
            "\n",
            "Dice score: 81.1551\n",
            "\n",
            "\n",
            "- Continue Training...\n",
            "\n",
            "\n",
            "- Loading Checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:   0%|          | 0/770 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 2: 100%|██████████| 770/770 [21:03<00:00,  1.64s/it, loss=0.184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCheck acc:   0%|          | 0/17 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Check acc: 100%|██████████| 17/17 [00:18<00:00,  1.10s/it, acc=75.3557]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Got an accuracy of 75.3557\n",
            "\n",
            "Dice score: 75.3594\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCheck acc:   0%|          | 0/23 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Check acc: 100%|██████████| 23/23 [00:23<00:00,  1.04s/it, acc=73.2326]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Got an accuracy of 73.2326\n",
            "\n",
            "Dice score: 73.2203\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Time taken: 105.717 min\n",
            "\n",
            "- Last Learning rate: 0.00081 \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3:   0%|          | 0/770 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 3: 100%|██████████| 770/770 [12:10<00:00,  1.05it/s, loss=0.169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCheck acc:   0%|          | 0/17 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Check acc: 100%|██████████| 17/17 [00:19<00:00,  1.13s/it, acc=82.5229]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Got an accuracy of 82.5229\n",
            "\n",
            "Dice score: 82.7867\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCheck acc:   0%|          | 0/23 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Check acc: 100%|██████████| 23/23 [00:26<00:00,  1.16s/it, acc=79.8062]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Got an accuracy of 79.8062\n",
            "\n",
            "Dice score: 79.7966\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Time taken: 119.702 min\n",
            "\n",
            "- Last Learning rate: 0.000729 \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 4:   0%|          | 0/770 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 4: 100%|██████████| 770/770 [12:12<00:00,  1.05it/s, loss=0.185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCheck acc:   0%|          | 0/17 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Check acc: 100%|██████████| 17/17 [00:17<00:00,  1.02s/it, acc=79.3042]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Got an accuracy of 79.3042\n",
            "\n",
            "Dice score: 79.153\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCheck acc:   0%|          | 0/23 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Check acc: 100%|██████████| 23/23 [00:24<00:00,  1.08s/it, acc=74.8252]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Got an accuracy of 74.8252\n",
            "\n",
            "Dice score: 74.8134\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Time taken: 133.036 min\n",
            "\n",
            "- Last Learning rate: 0.0006561 \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 5:   0%|          | 0/770 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 5: 100%|██████████| 770/770 [12:23<00:00,  1.04it/s, loss=0.221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCheck acc:   0%|          | 0/17 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Check acc: 100%|██████████| 17/17 [00:18<00:00,  1.07s/it, acc=83.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Got an accuracy of 83.567\n",
            "\n",
            "Dice score: 83.9707\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCheck acc:   0%|          | 0/23 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Check acc: 100%|██████████| 23/23 [00:23<00:00,  1.03s/it, acc=80.6561]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Got an accuracy of 80.6561\n",
            "\n",
            "Dice score: 80.6467\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Time taken: 146.533 min\n",
            "\n",
            "- Last Learning rate: 0.00059049 \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 6:   0%|          | 0/770 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 6:  57%|█████▋    | 437/770 [06:58<03:26,  1.61it/s, loss=0.162]"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Algorithm to Train, Save and Continue Training of Segmentation Models\n",
        "\n",
        "This is a training algorithm for segmentation tasks, that can be used to\n",
        "perform five tasks (training, saving, and testing models, but alose continue a\n",
        "training and saving image examples comparing prediction and label) in a diverse\n",
        "range of models. Next we will see which are the specific models applied using\n",
        "these algorithms, but we can adapt them to train a range of other segmenta-\n",
        "tion models, with just small changes (for classification models, please refers\n",
        "to the algorithms in the folder 'Classification\\train.py').\n",
        "\n",
        "This program runs together with the files 'utils.py', 'model.py' and 'dataset.\n",
        "py' to perform the training of the UResNet models (from 18 to 152 layers, as\n",
        "specified at 'model.py'), which are based in the encoder-decoder architecture,\n",
        "from the Raabin Dataset of Nucleus and Cytoplasm Ground Truths (available for\n",
        "download at https://raabindata.com/free-data/). To train other models, just\n",
        "specify your model at 'model.py', or simply load your model in the variable\n",
        "'model' inside this algorithm. To use other datasets, you need to change the\n",
        "file 'dataset.py' to load the new dataset as a 'torch.utils.data.Dataset'\n",
        "instance (see torch documentation for more information at\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial).\n",
        "\n",
        "Standard Training: To train a model from zero (or from the first epoch), just\n",
        "define the hyperparameters, as needed, and choose 'continue_training = False',\n",
        "and 'last_epoch = 0' (parameter only used for continue a training). In order to\n",
        "save your model, change 'save_model' to True, and to save images resultesd from\n",
        "the segmentaiton (from the validation dataset), in the folder 'saved_images'\n",
        "inside the 'root_folder', change 'save_images' to True. Variables 'test_model'\n",
        "and 'load_model' are for other popouses (see options below), and can set to\n",
        "False during the first training.\n",
        "\n",
        "Continue a Training: set 'continue_training = True' in the hyperparameters to\n",
        "continue a training, also setting 'last_epoch' with the number of epochs\n",
        "already trained (e.g. if you trained 10 epochs, and want to continue, set\n",
        "'last_epoch = 10'. Also the name of the pre-trained model has to exactly match\n",
        "chekpoint_dir in the 'root_folder' directory, and the 'csv' file with\n",
        "previous results, 'dictionary.csv', also has to be in 'root_folder'. The varia-\n",
        "ble 'laod_model' does not need to be 'True' (it is just to test, see below).\n",
        "\n",
        "Testing models: If you only want to test one or more models, just set\n",
        "'test_models = True', and specify the directory where the models to be tested\n",
        "are as a string in the variable 'test_models_dir'. If other options are also\n",
        "chosen, the test will take place in the and, after the other options finish.\n",
        "\n",
        "Loading and Testing One Model: if you want to test a model before continue a\n",
        "training, or just wants to load and test one model, choose 'load_model = True'.\n",
        "This will test the model chekpoint_dir stored in the 'root_folder'.\n",
        "\n",
        "\n",
        "Find more on the GitHub Repository:\n",
        "https://github.com/MarlonGarcia/attacking-white-blood-cells\n",
        "\n",
        "\n",
        "@author: Marlon Rodrigues Garcia\n",
        "@instit: University of São Paulo\n",
        "\"\"\"\n",
        "\n",
        "### Program  Header\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "# If running on Colabs, mounting drive\n",
        "run_on_colabs = True\n",
        "if run_on_colabs:\n",
        "    # Importing Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    # To import add current folder to path (import py files):\n",
        "    import sys\n",
        "    root_folder =     '//content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_dice_optimal'\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_dice_optimal'\n",
        "    chekpoint_dir = 'my_checkpoint6.pth.tar'\n",
        "else:\n",
        "    root_folder = 'D:/Users/Thales/Documents/TCC/IA/main/attacking-white-blood-cells/Segmentation'\n",
        "    test_models_dir = 'D:/Users/Thales/Documents/TCC/IA/main/attacking-white-blood-cells/Segmentation/results'\n",
        "    chekpoint_dir = 'D:/Users/Thales/Documents/TCC/IA/main/attacking-white-blood-cells/Segmentation/results/my_checkpoint33.pth.tar'\n",
        "\n",
        "# defining where to save results\n",
        "if run_on_colabs:\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_dice_optimal'\n",
        "else:\n",
        "    save_results_dir = 'D:/Users/Thales/Documents/TCC/IA/main/attacking-white-blood-cells/Segmentation/results'\n",
        "import os\n",
        "os.chdir(root_folder)\n",
        "\n",
        "#from model import *\n",
        "#from utils import *\n",
        "#from model import *\n",
        "#from utils import *\n",
        "\n",
        "\n",
        "#%% Defining Parameters and Path\n",
        "\n",
        "# defining hyperparameters\n",
        "learning_rate = 1e-4    # learning rate\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 6          # batch size\n",
        "num_epochs = 30         # number of epochs\n",
        "num_workers = 3         # number of workers (smaller or = n° processing units)\n",
        "clip_train = 1.00       # percentage to clip the train dataset (for tests)\n",
        "clip_valid = 1.00       # percentage to clip the valid dataset (for tests)\n",
        "valid_percent = 0.15    # use a percent of train dataset as validation dataset\n",
        "test_percent = 0.15     # a percent from training dataset (but do not excluded)\n",
        "start_save = 0          # epoch to start saving\n",
        "image_height = 512      # height to crop the image\n",
        "image_width = 640       # width to crop the image\n",
        "pin_memory = True\n",
        "load_model = True       # 'true' to load a model and test it, or use it\n",
        "save_model = True       # 'true' to save model trained after epoches\n",
        "continue_training = True # 'true' to load and continue training a model\n",
        "save_images = True      # saving example from predicted and original\n",
        "test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "last_epoch = 6        # when 'continue_training', it has to be the last epoch\n",
        "\n",
        "# defining the paths to datasets\n",
        "train_image_dir = ['/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/01',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/02',\n",
        "                      #  '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/03',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/04',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/05',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/06',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/07',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/pancreas/08',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/09',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/10',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/11',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/12',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/13',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/14',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/15',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/16',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/17',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/18',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/19',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/20',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/21',\n",
        "                      #  '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/22',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/23',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/24',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/25',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/26',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/pancreas/27',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/28',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/29',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/30',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/31'\n",
        "                       ]\n",
        "\n",
        "val_image_dir = ['/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/03',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/22'\n",
        "                       ]\n",
        "\n",
        "\n",
        "#%% Training Function\n",
        "\n",
        "# defining the training function\n",
        "def train_fn(loader, model, optimizer, loss_fn, scaler, schedule, epoch, last_lr):\n",
        "    loop = tqdm(loader, desc='Epoch '+str(epoch+1))\n",
        "\n",
        "    for batch_idx, (dictionary) in enumerate(loop):\n",
        "        image, label = dictionary\n",
        "        x, y = dictionary[image], dictionary[label]\n",
        "        x, y = x.to(device=device), y.to(device=device)\n",
        "        y = y.float()\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast() if torch.cuda.is_available() else torch.autocast('cpu'):\n",
        "            pred = model(x)\n",
        "            # cropping 'pred' for when the model changes the image dimensions\n",
        "            y = tf.center_crop(y, pred.shape[2:])\n",
        "            # calculating loss\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        if device == 'cuda':\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scale = scaler.get_scale()\n",
        "            scaler.update()\n",
        "        # if device='cpu', we cannot use 'scaler=torch.cuda.amp.GradScaler()':\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        # freeing space by deliting variables\n",
        "        loss_item = loss.item()\n",
        "        del loss, pred, y, x, image, label, dictionary\n",
        "        # updating tgdm loop\n",
        "        loop.set_postfix(loss=loss_item)\n",
        "    # deliting loader and loop\n",
        "    del loader, loop\n",
        "    # scheduling the learning rate and saving its last value\n",
        "    if scaler:\n",
        "        if scale >= scaler.get_scale():\n",
        "            schedule.step()\n",
        "            last_lr = schedule.get_last_lr()\n",
        "    else:\n",
        "        schedule.step()\n",
        "        last_lr = schedule.get_last_lr()\n",
        "\n",
        "    return loss_item, last_lr\n",
        "\n",
        "\n",
        "class CustomCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCrossEntropyLoss, self).__init__()\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Standard cross-entropy loss\n",
        "        loss = self.ce_loss(predictions, targets)\n",
        "\n",
        "        # Check if there are positive targets\n",
        "        positive_targets = (targets > 0).any()\n",
        "\n",
        "        # If no positive targets are present, return 0 loss\n",
        "        if not positive_targets:\n",
        "            return torch.tensor(0.0, requires_grad=True).to(predictions.device)\n",
        "        else:\n",
        "            return loss\n",
        "\n",
        "\n",
        "\n",
        "#%% Defining The main() Function\n",
        "def main():\n",
        "        # defining the model and casting to device\n",
        "    model = UResNet34(in_channels=3, num_classes=2).to(device)\n",
        "    # if binary classification, use BCEWithLogitsLoss and do not use logistic\n",
        "    # function inside the model (this loss has logistic already).\n",
        "    # loss_fn = nn.BCEWithLogitsLoss()\n",
        "    # for multiclass segmentation, use e.g. CrossEntropyLoss, and a logistic\n",
        "    # function inside the model (in its output), also changing the number of\n",
        "    # classes as desired in the model defined above (e.g. num_classes=3).\n",
        "    loss_fn = nn.L1Loss()\n",
        "    # loss_fn = nn.CrossEntropyLoss()\n",
        "    # loss_fn = CustomCrossEntropyLoss()\n",
        "    # pass 'lr=learning_rate' to Adam optim. to consider it, but it ahs its own\n",
        "    # way to schedule learning rate, so here it is not considered.\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    # SGD it is more stable, but has a lower accuracy in this segmentation:\n",
        "    # optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    schedule = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "    # if schedule is not used, please refer it as 'None'\n",
        "    # schedule = None\n",
        "\n",
        "    # loading dataLoaders\n",
        "    train_loader, test_loader, valid_loader = get_loaders(\n",
        "        train_image_dir=train_image_dir,\n",
        "        valid_percent=valid_percent,\n",
        "        test_percent=test_percent,\n",
        "        batch_size=batch_size,\n",
        "        image_height=image_height,\n",
        "        image_width=image_width,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        val_image_dir=val_image_dir,\n",
        "        clip_valid=clip_valid,\n",
        "        clip_train=clip_train\n",
        "    )\n",
        "\n",
        "    # if this program is just to load and test a model, next it loads a model\n",
        "    if load_model:\n",
        "        # loading checkpoint\n",
        "        os.chdir(root_folder)\n",
        "        if device == 'cuda':\n",
        "            load_checkpoint(torch.load(chekpoint_dir), model)\n",
        "        # if 'cpu', we need to pass 'map_location'\n",
        "        else:\n",
        "            load_checkpoint(torch.load(chekpoint_dir,\n",
        "                                       map_location=torch.device('cpu')), model)\n",
        "        check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "\n",
        "    if not load_model or continue_training:\n",
        "        # changing folder to save dictionary\n",
        "        os.chdir(save_results_dir)\n",
        "        # if 'continue_training==True', we load the model and continue training\n",
        "        if continue_training:\n",
        "            print('\\n- Continue Training...\\n')\n",
        "            start = time.time()\n",
        "            if device == 'cuda':\n",
        "                load_checkpoint(torch.load(chekpoint_dir), model,\n",
        "                                optimizer=optimizer)\n",
        "            else:\n",
        "                load_checkpoint(torch.load(chekpoint_dir,\n",
        "                                           map_location=torch.device('cpu')),\n",
        "                                           model, optimizer=optimizer)\n",
        "            # reading the csv 'dictionary.csv' as a dictionary\n",
        "            df = pd.read_csv('dictionary.csv')\n",
        "            temp = df.to_dict('split')\n",
        "            temp = temp['data']\n",
        "            dictionary = {'acc-valid':[], 'acc-test':[], 'loss':[], 'dice score-valid':[], 'dice score-test':[], 'time taken':[]}\n",
        "            for acc_valid, acc_test, loss, dice_score_valid, dice_score_test, time_item in temp:\n",
        "                dictionary['acc-valid'].append(acc_valid)\n",
        "                dictionary['acc-test'].append(acc_test)\n",
        "                dictionary['loss'].append(loss)\n",
        "                dictionary['dice score-valid'].append(dice_score_valid)\n",
        "                dictionary['dice score-test'].append(dice_score_test)\n",
        "                dictionary['time taken'].append(time_item)\n",
        "            # adding a last time to continue conting from here\n",
        "            last_time = time_item\n",
        "        # if it is the first epoch\n",
        "        elif not continue_training:\n",
        "            print('\\n- Start Training...\\n')\n",
        "            start = time.time()\n",
        "            # opening a 'loss' and 'acc' list, to save the data\n",
        "            dictionary = {'acc-valid':[], 'acc-test':[], 'loss':[], 'dice score-valid':[], 'dice score-test':[], 'time taken':[]}\n",
        "            acc_item_valid, loss_item, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device, title='Validating')\n",
        "            acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device, title='Testing')\n",
        "            print('\\n')\n",
        "            dictionary['acc-valid'].append(acc_item_valid)\n",
        "            dictionary['acc-test'].append(acc_item_test)\n",
        "            dictionary['loss'].append(loss_item)\n",
        "            dictionary['dice score-valid'].append(dice_score_valid)\n",
        "            dictionary['dice score-test'].append(dice_score_test)\n",
        "            # we added last_time here to sum it to the 'time taken' in the\n",
        "            # dictionary. it is done because if training is continued, we can\n",
        "            # sum the actual 'last_time' taken in previous training.\n",
        "            last_time = (time.time()-start)/60\n",
        "            dictionary['time taken'].append(last_time)\n",
        "\n",
        "        # with 'cpu' we can't use 'torch.cuda.amp.GradScaler()'\n",
        "        if device == 'cuda':\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "        else:\n",
        "            scaler = None\n",
        "        # to use 'last_lr' in 'train_fn', we have to define it first\n",
        "        last_lr = schedule.get_last_lr()\n",
        "        # begining image printing\n",
        "        fig, ax = plt.subplots()\n",
        "        # Criating a new start time (we have to sum this to 'last_time')\n",
        "        start = time.time()\n",
        "\n",
        "        # running epochs\n",
        "        for epoch in range(last_epoch, num_epochs):\n",
        "            # calling training function\n",
        "            loss_item, last_lr = train_fn(train_loader, model, optimizer,\n",
        "                                          loss_fn, scaler, schedule, epoch,\n",
        "                                          last_lr)\n",
        "            # appending resulted loss from training\n",
        "            dictionary['loss'].append(loss_item)\n",
        "            # saveing model\n",
        "            if save_model and epoch >= start_save -1:\n",
        "                # changing folder to save dictionary\n",
        "                os.chdir(save_results_dir)\n",
        "                checkpoint = {\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                }\n",
        "                save_checkpoint(checkpoint, filename='my_checkpoint'+str(epoch+1)+'.pth.tar')\n",
        "            # check accuracy\n",
        "            print('\\nValidating:')\n",
        "            acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "            print('Testing:')\n",
        "            acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "            stop = time.time()\n",
        "            dictionary['acc-valid'].append(acc_item_valid)\n",
        "            dictionary['acc-test'].append(acc_item_test)\n",
        "            dictionary['dice score-valid'].append(dice_score_valid)\n",
        "            dictionary['dice score-test'].append(dice_score_test)\n",
        "            dictionary['time taken'].append((stop-start)/60+last_time)\n",
        "            # saving some image examples to specified folder\n",
        "            if save_images:\n",
        "                # criating directory, if it does not exist\n",
        "                os.chdir(root_folder)\n",
        "                try: os.mkdir('saved_images')\n",
        "                except: pass\n",
        "                save_predictions_as_imgs(\n",
        "                    valid_loader, model, folder=os.path.join(root_folder,'saved_images'),\n",
        "                    device=device\n",
        "                )\n",
        "            # saving dictionary to a csv file\n",
        "            if save_model:\n",
        "                # changing folder to save dictionary\n",
        "                os.chdir(save_results_dir)\n",
        "                df = pd.DataFrame(dictionary, columns = ['acc-valid', 'acc-test',\n",
        "                                                         'loss', 'dice score-valid',\n",
        "                                                         'dice score-test', 'time taken'])\n",
        "                df.to_csv('dictionary.csv', index = False)\n",
        "\n",
        "            print('\\n- Time taken:',round((stop-start)/60+last_time,3),'min')\n",
        "            print('\\n- Last Learning rate:', round(last_lr[0],8),'\\n\\n')\n",
        "            # deleting variables for freeing space\n",
        "            del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid,\n",
        "            loss_item, stop\n",
        "            try: del checkpoint\n",
        "            except: pass\n",
        "\n",
        "            # continue image printing\n",
        "            if epoch == last_epoch:\n",
        "                ax.plot(np.asarray(dictionary['acc-valid']), 'C1', label ='accuracy-validation')\n",
        "                ax.plot(np.asarray(dictionary['acc-test']), 'C2', label ='accuracy-test')\n",
        "                ax.plot(np.asarray(dictionary['dice score-valid']), 'C4', label = 'dice score-validation')\n",
        "                ax.plot(np.asarray(dictionary['dice score-test']), 'C5', label = 'dice score-test')\n",
        "                ax.plot(np.asarray(dictionary['loss']), 'C3', label = 'loss')\n",
        "                plt.legend()\n",
        "                ax.set_xlabel('Epochs')\n",
        "                ax.set_ylabel('Accuracy, Loss, and Dice score')\n",
        "                plt.pause(0.5)\n",
        "            else:\n",
        "                ax.plot(np.asarray(dictionary['acc-valid']), 'C1')\n",
        "                ax.plot(np.asarray(dictionary['acc-test']), 'C2')\n",
        "                ax.plot(np.asarray(dictionary['dice score-valid']), 'C4')\n",
        "                ax.plot(np.asarray(dictionary['dice score-test']), 'C5')\n",
        "                ax.plot(np.asarray(dictionary['loss']), 'C3')\n",
        "            plt.show()\n",
        "            plt.pause(0.5)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "#%% Defining test function\n",
        "\n",
        "def testing_models():\n",
        "\n",
        "    model = UResNet50(in_channels=3, num_classes=2).to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    schedule = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
        "    # getting the 'valid_loader'\n",
        "    e, train_loader, valid_loader = get_loaders(\n",
        "        train_image_dir=train_image_dir,\n",
        "        # csv_file_train=csv_file_train,\n",
        "        valid_percent=valid_percent,\n",
        "        test_percent=test_percent,\n",
        "        batch_size=batch_size,\n",
        "        image_height=image_height,\n",
        "        image_width=image_width,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        clip_valid=clip_valid,\n",
        "        clip_train=clip_train\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    os.chdir(test_models_dir)\n",
        "    for file in os.listdir(test_models_dir):\n",
        "        print('\\n\\n')\n",
        "        if 'my_checkpoint' in file:\n",
        "            # checking accuracy\n",
        "            if device == 'cuda':\n",
        "                load_checkpoint(torch.load(file), model)\n",
        "            else:\n",
        "                load_checkpoint(torch.load(file,\n",
        "                                           map_location=torch.device('cpu')),\n",
        "                                           model)\n",
        "            print('\\n- Model:', file)\n",
        "            acc, loss,dice = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "            # acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "            print('\\n- Acc:',round(acc,3),'; loss:',round(loss,3),'; dice:',round(dice,3))\n",
        "\n",
        "# if (__name__ == '__main__') and (test_models == True):\n",
        "#     testing_models()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "c9xwLZJbZ32T",
        "outputId": "9efe7581-23fc-4aa5-f0ca-f20536f2d53f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f6dd085494e9>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0msave_results_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#from model import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6'"
          ]
        }
      ],
      "source": [
        "  #teste com array ortogonal para definir melhores parametros\n",
        "\"\"\"\n",
        "@author: THALES PIMENTEL ZUANAZZI\n",
        "@instituto: UNESP\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "  A B C D\n",
        "1 1 1 1 1\n",
        "2 1 2 2 3\n",
        "3 1 3 3 2\n",
        "4 2 1 2 2\n",
        "5 2 2 3 1\n",
        "6 2 3 1 3\n",
        "7 3 1 3 3\n",
        "8 3 2 1 2\n",
        "9 3 3 2 1\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "B = learning_rate = 5e-4 1e-3 1e-4\n",
        "A = batch_size = 8 6 12\n",
        "C = model = UResNet34(in_channels=3, num_classes=2).to(device) UResNet18(in_channels=3, num_classes=2).to(device) UResNet50(in_channels=3, num_classes=2).to(device)\n",
        "D = loss = nn.CrossEntropyLoss()  CustomLoss()   nn.L1Loss()\n",
        "\"\"\"\n",
        "\n",
        "### Program  Header\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# running on Colabs, mounting drive\n",
        "run_on_colabs = True\n",
        "# Importing Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# To import add current folder to path (import py files):\n",
        "import sys\n",
        "root_folder = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6'\n",
        "#              /content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6\n",
        "sys.path.append(root_folder)\n",
        "test_models_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6'\n",
        "chekpoint_dir = 'my_checkpoint10.pth.tar'\n",
        "\n",
        "# defining where to save results\n",
        "save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6'\n",
        "import os\n",
        "os.chdir(root_folder)\n",
        "\n",
        "#from model import *\n",
        "#from utils import *\n",
        "\n",
        "# defining the paths to datasets\n",
        "train_image_dir = ['/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/01',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/02',\n",
        "                      #  '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/03',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/04',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/05',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/06',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/07',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/pancreas/08',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/09',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/10',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/11',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/12',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/13',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/14',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/15',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/16',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/17',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/18',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/19',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/20',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/21',\n",
        "                      #  '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/22',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/abdominal_wall/23',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/24',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/25',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/26',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/pancreas/27',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/28',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/29',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/30',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/31'\n",
        "                       ]\n",
        "\n",
        "val_image_dir = ['/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/03',\n",
        "                       '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Datasets/DSAD/liver/22'\n",
        "                       ]\n",
        "\n",
        "\n",
        "#%% Training Function\n",
        "\n",
        "# defining the training function\n",
        "def train_fn(loader, model, optimizer, loss_fn, scaler, schedule, epoch, last_lr):\n",
        "    loop = tqdm(loader, desc='Epoch '+str(epoch+1))\n",
        "\n",
        "    for batch_idx, (dictionary) in enumerate(loop):\n",
        "        image, label = dictionary\n",
        "        x, y = dictionary[image], dictionary[label]\n",
        "        x, y = x.to(device=device), y.to(device=device)\n",
        "        y = y.float()\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast() if torch.cuda.is_available() else torch.autocast('cpu'):\n",
        "            pred = model(x)\n",
        "            # cropping 'pred' for when the model changes the image dimensions\n",
        "            y = tf.center_crop(y, pred.shape[2:])\n",
        "            # calculating loss\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        if device == 'cuda':\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scale = scaler.get_scale()\n",
        "            scaler.update()\n",
        "        # if device='cpu', we cannot use 'scaler=torch.cuda.amp.GradScaler()':\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        # freeing space by deliting variables\n",
        "        loss_item = loss.item()\n",
        "        del loss, pred, y, x, image, label, dictionary\n",
        "        # updating tgdm loop\n",
        "        loop.set_postfix(loss=loss_item)\n",
        "    # deliting loader and loop\n",
        "    del loader, loop\n",
        "    # scheduling the learning rate and saving its last value\n",
        "    if scaler:\n",
        "        if scale >= scaler.get_scale():\n",
        "            schedule.step()\n",
        "            last_lr = schedule.get_last_lr()\n",
        "    else:\n",
        "        schedule.step()\n",
        "        last_lr = schedule.get_last_lr()\n",
        "\n",
        "    return loss_item, last_lr\n",
        "\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, alpha=1.0, beta=1.0):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.alpha = alpha  # Weight for true positive loss\n",
        "        self.beta = beta   # Weight for false negative loss\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Assuming predictions and targets are binary (0 or 1)\n",
        "        # Calculate true positives\n",
        "        true_positives = (predictions * targets)\n",
        "\n",
        "        # Calculate false negatives\n",
        "        false_negatives = ((1 - predictions) * targets)\n",
        "\n",
        "        # Compute loss based on true positives and false negatives\n",
        "        true_positive_loss = torch.mean((true_positives - targets) ** 2)\n",
        "        false_negative_loss = torch.mean((false_negatives) ** 2)\n",
        "\n",
        "        # Total loss with weighted components\n",
        "        loss = (self.alpha * true_positive_loss) + (self.beta * false_negative_loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "#%% Defining The main() Function\n",
        "model1 = UResNet34(in_channels=3, num_classes=2).to('cuda')\n",
        "loss1 = CustomLoss()\n",
        "def main():\n",
        "    model = model1\n",
        "    loss_fn = loss1\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    schedule = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "    # loading dataLoaders\n",
        "    train_loader, test_loader, valid_loader = get_loaders(\n",
        "        train_image_dir=train_image_dir,\n",
        "        valid_percent=valid_percent,\n",
        "        test_percent=test_percent,\n",
        "        batch_size=batch_size,\n",
        "        image_height=image_height,\n",
        "        image_width=image_width,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        val_image_dir=val_image_dir,\n",
        "        clip_valid=clip_valid,\n",
        "        clip_train=clip_train\n",
        "    )\n",
        "\n",
        "    # if this program is just to load and test a model, next it loads a model\n",
        "    if load_model:\n",
        "        # loading checkpoint\n",
        "        os.chdir(root_folder)\n",
        "        if device == 'cuda':\n",
        "            load_checkpoint(torch.load(chekpoint_dir), model)\n",
        "        # if 'cpu', we need to pass 'map_location'\n",
        "        else:\n",
        "            load_checkpoint(torch.load(chekpoint_dir,\n",
        "                                       map_location=torch.device('cpu')), model)\n",
        "        check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "\n",
        "    if not load_model or continue_training:\n",
        "        # changing folder to save dictionary\n",
        "        os.chdir(save_results_dir)\n",
        "        # if 'continue_training==True', we load the model and continue training\n",
        "        if continue_training:\n",
        "            print('\\n- Continue Training...\\n')\n",
        "            start = time.time()\n",
        "            if device == 'cuda':\n",
        "                load_checkpoint(torch.load(chekpoint_dir), model,\n",
        "                                optimizer=optimizer)\n",
        "            else:\n",
        "                load_checkpoint(torch.load(chekpoint_dir,\n",
        "                                           map_location=torch.device('cpu')),\n",
        "                                           model, optimizer=optimizer)\n",
        "            # reading the csv 'dictionary.csv' as a dictionary\n",
        "            df = pd.read_csv('dictionary.csv')\n",
        "            temp = df.to_dict('split')\n",
        "            temp = temp['data']\n",
        "            dictionary = {'acc-valid':[], 'acc-test':[], 'loss':[], 'dice score-valid':[], 'dice score-test':[], 'time taken':[]}\n",
        "            for acc_valid, acc_test, loss, dice_score_valid, dice_score_test, time_item in temp:\n",
        "                dictionary['acc-valid'].append(acc_valid)\n",
        "                dictionary['acc-test'].append(acc_test)\n",
        "                dictionary['loss'].append(loss)\n",
        "                dictionary['dice score-valid'].append(dice_score_valid)\n",
        "                dictionary['dice score-test'].append(dice_score_test)\n",
        "                dictionary['time taken'].append(time_item)\n",
        "            # adding a last time to continue conting from here\n",
        "            last_time = time_item\n",
        "        # if it is the first epoch\n",
        "        elif not continue_training:\n",
        "            print('\\n- Start Training...\\n')\n",
        "            start = time.time()\n",
        "            # opening a 'loss' and 'acc' list, to save the data\n",
        "            dictionary = {'acc-valid':[], 'acc-test':[], 'loss':[], 'dice score-valid':[], 'dice score-test':[], 'time taken':[]}\n",
        "            acc_item_valid, loss_item, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device, title='Validating')\n",
        "            acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device, title='Testing')\n",
        "            print('\\n')\n",
        "            dictionary['acc-valid'].append(acc_item_valid)\n",
        "            dictionary['acc-test'].append(acc_item_test)\n",
        "            dictionary['loss'].append(loss_item)\n",
        "            dictionary['dice score-valid'].append(dice_score_valid)\n",
        "            dictionary['dice score-test'].append(dice_score_test)\n",
        "            # we added last_time here to sum it to the 'time taken' in the\n",
        "            # dictionary. it is done because if training is continued, we can\n",
        "            # sum the actual 'last_time' taken in previous training.\n",
        "            last_time = (time.time()-start)/60\n",
        "            dictionary['time taken'].append(last_time)\n",
        "\n",
        "        # with 'cpu' we can't use 'torch.cuda.amp.GradScaler()'\n",
        "        if device == 'cuda':\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "        else:\n",
        "            scaler = None\n",
        "        # to use 'last_lr' in 'train_fn', we have to define it first\n",
        "        last_lr = schedule.get_last_lr()\n",
        "        # begining image printing\n",
        "        fig, ax = plt.subplots()\n",
        "        # Criating a new start time (we have to sum this to 'last_time')\n",
        "        start = time.time()\n",
        "\n",
        "        # running epochs\n",
        "        for epoch in range(last_epoch, num_epochs):\n",
        "            # calling training function\n",
        "            loss_item, last_lr = train_fn(train_loader, model, optimizer,\n",
        "                                          loss_fn, scaler, schedule, epoch,\n",
        "                                          last_lr)\n",
        "            # appending resulted loss from training\n",
        "            dictionary['loss'].append(loss_item)\n",
        "            # saveing model\n",
        "            if save_model and epoch >= start_save -1:\n",
        "                # changing folder to save dictionary\n",
        "                os.chdir(save_results_dir)\n",
        "                checkpoint = {\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                }\n",
        "                save_checkpoint(checkpoint, filename='my_checkpoint'+str(epoch+1)+'.pth.tar')\n",
        "            # check accuracy\n",
        "            print('\\nValidating:')\n",
        "            acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "            print('Testing:')\n",
        "            acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "            stop = time.time()\n",
        "            dictionary['acc-valid'].append(acc_item_valid)\n",
        "            dictionary['acc-test'].append(acc_item_test)\n",
        "            dictionary['dice score-valid'].append(dice_score_valid)\n",
        "            dictionary['dice score-test'].append(dice_score_test)\n",
        "            dictionary['time taken'].append((stop-start)/60+last_time)\n",
        "            # saving some image examples to specified folder\n",
        "            if save_images:\n",
        "                # criating directory, if it does not exist\n",
        "                os.chdir(root_folder)\n",
        "                try: os.mkdir('saved_images')\n",
        "                except: pass\n",
        "                save_predictions_as_imgs(\n",
        "                    valid_loader, model, folder=os.path.join(root_folder,'saved_images'),\n",
        "                    device=device\n",
        "                )\n",
        "            # saving dictionary to a csv file\n",
        "            if save_model:\n",
        "                # changing folder to save dictionary\n",
        "                os.chdir(save_results_dir)\n",
        "                df = pd.DataFrame(dictionary, columns = ['acc-valid', 'acc-test',\n",
        "                                                         'loss', 'dice score-valid',\n",
        "                                                         'dice score-test', 'time taken'])\n",
        "                df.to_csv('dictionary.csv', index = False)\n",
        "\n",
        "            print('\\n- Time taken:',round((stop-start)/60+last_time,3),'min')\n",
        "            print('\\n- Last Learning rate:', round(last_lr[0],8),'\\n\\n')\n",
        "            # deleting variables for freeing space\n",
        "            del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "            try: del checkpoint\n",
        "            except: pass\n",
        "\n",
        "            # continue image printing\n",
        "            if epoch == last_epoch:\n",
        "                ax.plot(np.asarray(dictionary['acc-valid']), 'C1', label ='accuracy-validation')\n",
        "                ax.plot(np.asarray(dictionary['acc-test']), 'C2', label ='accuracy-test')\n",
        "                ax.plot(np.asarray(dictionary['dice score-valid']), 'C4', label = 'dice score-validation')\n",
        "                ax.plot(np.asarray(dictionary['dice score-test']), 'C5', label = 'dice score-test')\n",
        "                ax.plot(np.asarray(dictionary['loss']), 'C3', label = 'loss')\n",
        "                plt.legend()\n",
        "                ax.set_xlabel('Epochs')\n",
        "                ax.set_ylabel('Accuracy, Loss, and Dice score')\n",
        "                plt.pause(0.5)\n",
        "            else:\n",
        "                ax.plot(np.asarray(dictionary['acc-valid']), 'C1')\n",
        "                ax.plot(np.asarray(dictionary['acc-test']), 'C2')\n",
        "                ax.plot(np.asarray(dictionary['dice score-valid']), 'C4')\n",
        "                ax.plot(np.asarray(dictionary['dice score-test']), 'C5')\n",
        "                ax.plot(np.asarray(dictionary['loss']), 'C3')\n",
        "            plt.show()\n",
        "            plt.pause(0.5)\n",
        "\n",
        "#%% Defining Parameters and Path\n",
        "\n",
        "# defining hyperparameters\n",
        "learning_rate = 5e-4    # learning rate\n",
        "device = 'cuda' #if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 8          # batch size\n",
        "num_epochs = 20         # number of epochs\n",
        "num_workers = 3         # number of workers (smaller or = n° processing units)\n",
        "clip_train = 1.00       # percentage to clip the train dataset (for tests)\n",
        "clip_valid = 1.00       # percentage to clip the valid dataset (for tests)\n",
        "valid_percent = 0.15    # use a percent of train dataset as validation dataset\n",
        "test_percent = 0.15     # a percent from training dataset (but do not excluded)\n",
        "start_save = 0          # epoch to start saving\n",
        "image_height = 512      # height to crop the image\n",
        "image_width = 640       # width to crop the image\n",
        "pin_memory = True\n",
        "load_model = True      # 'true' to load a model and test it, or use it\n",
        "save_model = False       # 'true' to save model trained after epoches\n",
        "continue_training = False # 'true' to load and continue training a model\n",
        "save_images = False      # saving example from predicted and original\n",
        "test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "last_epoch = 20         # when 'continue_training', it has to be the last epoch\n",
        "\n",
        "# Using nested list comprehensions to create a 9x20x4 list filled with initial_value\n",
        "rows = 9\n",
        "columns = 20\n",
        "depth = 4\n",
        "initial_value = 0\n",
        "\n",
        "save = [[[initial_value for j in range(depth)] for i in range(columns)] for k in range(rows)]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  #serão 9 testes, se parar no meio do caminha terá ue ver como resolver\n",
        "\n",
        "    # primeiro\n",
        "    print('### First ###')\n",
        "    learning_rate = 5e-4    # learning rate\n",
        "    batch_size = 8          # batch size\n",
        "    model1 = UResNet34(in_channels=3, num_classes=2).to(device)\n",
        "    loss1 = nn.CrossEntropyLoss()  #CustomLoss()\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_1'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_1'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_1'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_1/my_checkpoint7.pth.tar'\n",
        "    load_model = True      # 'true' to load a model and test it, or use it\n",
        "    save_model = False       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 20\n",
        "    main()\n",
        "    for i in range(1,last_epoch):\n",
        "      l = 1\n",
        "      last_epoch = i\n",
        "      main()\n",
        "      acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "      acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "      save[0][i-1][l] = acc_item_valid\n",
        "      save[2][i-1][l] = dice_score_valid\n",
        "      save[3][i-1][l] = acc_item_test\n",
        "      save[4][i-1][l] = dice_score_test\n",
        "      del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "\n",
        "    # segundo\n",
        "    print('### Second ###')\n",
        "    device = 'cuda'\n",
        "    batch_size = 8 # 6 12\n",
        "    learning_rate =1e-3 #5e-4 1e-3 1e-4\n",
        "    loss1 = CustomLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet50(in_channels=3, num_classes=2).to('cuda') #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder =      '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_2'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir =  '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_2'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_2/my_checkpoint14.pth.tar'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_2'\n",
        "    last_epoch = 20\n",
        "    load_model = True      # 'true' to load a model and test it, or use it\n",
        "    save_model = False       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "    main()\n",
        "    for i in range(1,last_epoch):\n",
        "      l = 2\n",
        "      last_epoch = i\n",
        "      main()\n",
        "      acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "      acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "      save[0][i-1][l] = acc_item_valid\n",
        "      save[2][i-1][l] = dice_score_valid\n",
        "      save[3][i-1][l] = acc_item_test\n",
        "      save[4][i-1][l] = dice_score_test\n",
        "      del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "\n",
        "    # terceiro\n",
        "    print('### Third ###')\n",
        "    batch_size = 8 # 6 12\n",
        "    learning_rate =1e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.L1Loss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet18(in_channels=3, num_classes=2).to('cuda') #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_3'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_3'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_3'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_3/my_checkpoint14.pth.tar'\n",
        "    last_epoch = 20\n",
        "    load_model = True      # 'true' to load a model and test it, or use it\n",
        "    save_model = False       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "    main()\n",
        "    for i in range(1,last_epoch):\n",
        "      l = 3\n",
        "      last_epoch = i\n",
        "      main()\n",
        "      acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "      acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "      save[0][i-1][l] = acc_item_valid\n",
        "      save[2][i-1][l] = dice_score_valid\n",
        "      save[3][i-1][l] = acc_item_test\n",
        "      save[4][i-1][l] = dice_score_test\n",
        "      del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "\n",
        "    # quarto\n",
        "    print('### Fourth ###')\n",
        "    batch_size = 6 #8 6 12\n",
        "    learning_rate =5e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = CustomLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet18(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_4'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_4'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_4'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_4/my_checkpoint18.pth.tar'\n",
        "    load_model = True      # 'true' to load a model and test it, or use it\n",
        "    save_model = False       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 20\n",
        "    main()\n",
        "    for i in range(1,last_epoch):\n",
        "      l = 4\n",
        "      last_epoch = i\n",
        "      main()\n",
        "      acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "      acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "      save[0][i-1][l] = acc_item_valid\n",
        "      save[2][i-1][l] = dice_score_valid\n",
        "      save[3][i-1][l] = acc_item_test\n",
        "      save[4][i-1][l] = dice_score_test\n",
        "      del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "\n",
        "    # quinto\n",
        "    print('### Fifth ###')\n",
        "    batch_size = 6 #8 6 12\n",
        "    learning_rate = 1e-3 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.L1Loss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet34(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_5'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_5'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_5'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_5/my_checkpoint12.pth.tar'\n",
        "    load_model = True      # 'true' to load a model and test it, or use it\n",
        "    save_model = False       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 20\n",
        "    main()\n",
        "    for i in range(1,last_epoch):\n",
        "      l = 5\n",
        "      last_epoch = i\n",
        "      main()\n",
        "      acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "      acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "      save[0][i-1][l] = acc_item_valid\n",
        "      save[2][i-1][l] = dice_score_valid\n",
        "      save[3][i-1][l] = acc_item_test\n",
        "      save[4][i-1][l] = dice_score_test\n",
        "      del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "\n",
        "    # sexto\n",
        "    print('### Sixth ###')\n",
        "    batch_size = 6 #8 6 12\n",
        "    learning_rate = 1e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.CrossEntropyLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet50(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_6'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir =  '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_6'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_6'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_6/my_checkpoint19.pth.tar'\n",
        "    load_model = True      # 'true' to load a model and test it, or use it\n",
        "    save_model = False       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 20\n",
        "    main()\n",
        "    for i in range(1,last_epoch):\n",
        "      l = 6\n",
        "      last_epoch = i\n",
        "      main()\n",
        "      acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "      acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "      save[0][i-1][l] = acc_item_valid\n",
        "      save[2][i-1][l] = dice_score_valid\n",
        "      save[3][i-1][l] = acc_item_test\n",
        "      save[4][i-1][l] = dice_score_test\n",
        "      del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "\n",
        "    # setimo\n",
        "    print('### Seventh ###')\n",
        "    batch_size = 12 #8 6 12\n",
        "    learning_rate = 5e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.L1Loss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet50(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_7'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_7'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_7'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_7/my_checkpoint11.pth.tar'\n",
        "    load_model = True      # 'true' to load a model and test it, or use it\n",
        "    save_model = False       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 20\n",
        "    main()\n",
        "    for i in range(1,last_epoch):\n",
        "      l = 7\n",
        "      last_epoch = i\n",
        "      main()\n",
        "      acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "      acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "      save[0][i-1][l] = acc_item_valid\n",
        "      save[2][i-1][l] = dice_score_valid\n",
        "      save[3][i-1][l] = acc_item_test\n",
        "      save[4][i-1][l] = dice_score_test\n",
        "      del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "\n",
        "    # oitavo\n",
        "    print('### Eighth ###')\n",
        "    batch_size = 12 #8 6 12\n",
        "    learning_rate = 1e-3 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.CrossEntropyLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet18(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_8'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_8'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_8'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_8/my_checkpoint17.pth.tar'\n",
        "    load_model = True      # 'true' to load a model and test it, or use it\n",
        "    save_model = False       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 20\n",
        "    main()\n",
        "    for i in range(1,last_epoch):\n",
        "      l = 8\n",
        "      last_epoch = i\n",
        "      main()\n",
        "      acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "      acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "      save[0][i-1][l] = acc_item_valid\n",
        "      save[2][i-1][l] = dice_score_valid\n",
        "      save[3][i-1][l] = acc_item_test\n",
        "      save[4][i-1][l] = dice_score_test\n",
        "      del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "    # nono\n",
        "    print('### Ninth ###')\n",
        "    batch_size = 12 #8 6 12\n",
        "    learning_rate = 1e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = CustomLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet34(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_9'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_9'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_9'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. de Óptica Biomédica/Desenvolvido pelos Pesquisadores/Thales Pimentel Zuanazzi/Segmentação/teste_6/teste_9/my_checkpoint12.pth.tar'\n",
        "    load_model = True      # 'true' to load a model and test it, or use it\n",
        "    save_model = False       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = True     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 20\n",
        "    main()\n",
        "    for i in range(1,last_epoch):\n",
        "      l = 9\n",
        "      last_epoch = i\n",
        "      main()\n",
        "      acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "      acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "      save[0][i-1][l] = acc_item_valid\n",
        "      save[2][i-1][l] = dice_score_valid\n",
        "      save[3][i-1][l] = acc_item_test\n",
        "      save[4][i-1][l] = dice_score_test\n",
        "      del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "\n",
        "print(save)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
