{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nV7r8fuC_pu",
        "outputId": "a73f314f-4214-444b-8deb-2ac74eafb929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: TorchAudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from TorchAudio) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->TorchAudio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->TorchAudio) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->TorchAudio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->TorchAudio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->TorchAudio) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->TorchAudio) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->TorchAudio) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->TorchAudio) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->TorchAudio) (1.3.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (3.0.6)\n",
            "Collecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (0.16.0+cu121)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (4.66.1)\n",
            "Collecting requests~=2.25.1 (from torchattacks)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.23.5)\n",
            "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.2->torchattacks) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Installing collected packages: urllib3, idna, chardet, requests, torchattacks\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.17.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.14.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.33 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.18\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#this code is runed on google colabs\n",
        "!pip install torchmetrics\n",
        "!pip install tqdm\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install TorchAudio\n",
        "!pip install Cython\n",
        "!pip install torchattacks\n",
        "!pip install opencv-python\n",
        "!pip install PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEKMw_e1DPWt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class DresdenDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        # Initialize the dataset with the directory of images and optional transforms\n",
        "        self.image_dir = image_dir\n",
        "        basename = os.path.basename(image_dir)\n",
        "        self.label_dir = os.path.join((os.path.dirname(image_dir)), basename, 'merged')\n",
        "        self.transform = transform\n",
        "\n",
        "        # Collect filenames of images and masks from the directory\n",
        "        self.image_names = [filename for filename in os.listdir(image_dir) if filename.startswith(\"image\")]\n",
        "        self.label_names = [filename for filename in os.listdir(image_dir) if filename.startswith(\"mask\")]\n",
        "\n",
        "        # Sort the image and label filenames based on their numeric identifiers\n",
        "        self.image_names.sort(key=lambda x: int(x[5:7]))  # Extract and sort based on the number in \"imageXX.png\"\n",
        "        self.label_names.sort(key=lambda x: int(x[4:6]))  # Extract and sort based on the number in \"maskXX.png\"\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of images in the dataset\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def classes(self):\n",
        "        # Define the classes in the dataset\n",
        "        return torch.Tensor([0, 1])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieve an item by its index\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Load the image and its corresponding label\n",
        "        image = np.array(Image.open(os.path.join(self.image_dir, self.image_names[idx])).convert('RGB'))\n",
        "        label1 = np.array(Image.open(os.path.join(self.image_dir, self.label_names[idx])).convert('RGB'))\n",
        "\n",
        "        # Process the label image to create binary mask labels\n",
        "        label = np.zeros(np.shape(label1), np.uint8)[:, :, 0:2]\n",
        "        label[:, :, 0][label1[:, :, 0] > 125] = 1  # Assign class 1 to pixels with a value > 125 in the red channel\n",
        "        label[:, :, 1][label1[:, :, 0] < 125] = 1  # Assign class 1 to pixels with a value < 125 in the red channel\n",
        "\n",
        "        # Create a dictionary with the processed image and label\n",
        "        dictionary = {'image0': image, 'image1': label}\n",
        "\n",
        "        # Apply transforms, if any\n",
        "        if self.transform is not None:\n",
        "            dictionary = self.transform(dictionary)\n",
        "\n",
        "        return dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXVPEOTtDRfF",
        "outputId": "b48c421f-806c-4df3-c694-be4dc722ba89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1000, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "'''\n",
        "UResNet Class: Combines U-Net and ResNet architectures for segmentation tasks. It includes both contracting (downward) and expanding (upward) paths with long skip connections.\n",
        "Constructor (__init__): Initializes layers and sets up the network structure.\n",
        "Forward Method: Defines how the input data flows through the network, including the integration of long skip connections.\n",
        "_make_layer Method: Helper function to create layers of blocks (either standard or bottleneck).\n",
        "Factory Functions (UResNet18, UResNet34, etc.): These functions provide easy creation of UResNet models with different depths.\n",
        "Test Function: A simple function to verify the model's output dimensions.\n",
        "'''\n",
        "# Custom Sequential class to handle multiple inputs\n",
        "class mySequential(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        for module in self._modules.values():\n",
        "            # If inputs is a tuple, apply the module to all elements in the tuple\n",
        "            if type(inputs) == tuple:\n",
        "                inputs = module(*inputs)\n",
        "            else:\n",
        "                inputs = module(inputs)\n",
        "        return inputs\n",
        "\n",
        "class block_standard(nn.Module):\n",
        "    # Block expansion factor for standard blocks\n",
        "    expansion: int = 1\n",
        "    # Factor to adjust the out_channels in standard blocks\n",
        "    out_multiply: int = 2\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1, up=False):\n",
        "        super(block_standard, self).__init__()\n",
        "        self.up = up\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # Convolutional layers setup, with or without transpose (upscaling)\n",
        "        if self.up:\n",
        "            # For upscaling\n",
        "            self.conv1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=stride, stride=stride)\n",
        "        else:\n",
        "            # Regular convolution\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "\n",
        "    def forward(self, x, long_skip=None):\n",
        "        identity = x\n",
        "        # Forward pass through layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        # Apply identity downsample if exists\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        # Concatenate with long skip connection if exists\n",
        "        if long_skip is not None:\n",
        "            x = torch.cat((x, long_skip), dim=1)\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "\n",
        "        del identity  # Explicit memory management\n",
        "\n",
        "        return x, long_skip\n",
        "\n",
        "\n",
        "class block_bottleneck(nn.Module):\n",
        "    # Block expansion factor for bottleneck blocks\n",
        "    expansion: int = 4\n",
        "    # Factor to adjust the out_channels in bottleneck blocks\n",
        "    out_multiply: int = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, identity_scale=None, stride=1, up=False):\n",
        "        super(block_bottleneck, self).__init__()\n",
        "        self.up = up\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # Adjust expansion factor based on upscaling\n",
        "        self.expansion = 2 if self.up else 4\n",
        "\n",
        "        # Convolutional layers setup, with or without transpose (upscaling)\n",
        "        if self.up:\n",
        "            self.conv1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=stride, stride=stride)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Second convolutional layer\n",
        "        if self.up:\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        else:\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_scale = identity_scale\n",
        "\n",
        "    def forward(self, x, long_skip=None):\n",
        "        identity = x\n",
        "        # Forward pass through layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        # Apply identity scale if exists\n",
        "        if self.identity_scale is not None:\n",
        "            identity = self.identity_scale(identity)\n",
        "\n",
        "        # Concatenate with long skip connection if exists\n",
        "        if long_skip is not None:\n",
        "            x = torch.cat((x, long_skip), dim=1)\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "\n",
        "        del identity  # Explicit memory management\n",
        "\n",
        "        return x, long_skip\n",
        "    \n",
        "class UResNet(nn.Module): \n",
        "    # UResNet: U-Net combined with ResNet architecture. \n",
        "    # Designed for segmentation tasks with deep feature extraction.\n",
        "\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        # Initialize UResNet model\n",
        "        # Parameters:\n",
        "        #   block: Type of block to use (standard or bottleneck)\n",
        "        #   layers: List indicating the number of blocks at each layer\n",
        "        #   image_channels: Number of input channels (e.g., 3 for RGB images)\n",
        "        #   num_classes: Number of output classes for segmentation\n",
        "\n",
        "        super(UResNet, self).__init__()\n",
        "\n",
        "        # Initial convolutional layer\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Placeholder for long skip connections\n",
        "        self.long_skip = []\n",
        "\n",
        "        # Constructing downward (contracting) path using ResNet layers\n",
        "        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
        "        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
        "        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
        "\n",
        "        # Constructing upward (expanding) path using ResNet layers\n",
        "        self.layer5 = self._make_layer(block, layers[3], out_channels=512, stride=2, up=True)\n",
        "        self.layer6 = self._make_layer(block, layers[2], out_channels=256, stride=2, up=True)\n",
        "        self.layer7 = self._make_layer(block, layers[1], out_channels=128, stride=2, up=True)\n",
        "        self.layer8 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "\n",
        "        # Final convolutional layers to refine the output\n",
        "        self.conv_last1 = nn.ConvTranspose2d(self.in_channels, 64, kernel_size=2, stride=2, padding=0)\n",
        "        self.conv_last2 = nn.ConvTranspose2d(64*2, num_classes, kernel_size=2, stride=2, padding=0)\n",
        "        self.bn2 = nn.BatchNorm2d(num_classes)\n",
        "        self.Softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass of UResNet\n",
        "        # x: Input tensor\n",
        "\n",
        "        # Initial layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Storing feature maps for long skip connections\n",
        "        self.long_skip = [0, 0, 0, 0]\n",
        "        self.long_skip[0] = x\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Downward path\n",
        "        x, temp = self.layer1(x, None)\n",
        "        self.long_skip[1] = x\n",
        "        x, temp = self.layer2(x, None)\n",
        "        self.long_skip[2] = x\n",
        "        x, temp = self.layer3(x, None)\n",
        "        self.long_skip[3] = x\n",
        "        x, temp = self.layer4(x, None)\n",
        "\n",
        "        # Reverse the order of long skips for upward path\n",
        "        self.long_skip = self.long_skip[::-1]\n",
        "\n",
        "        # Upward path with long skip connections\n",
        "        x, temp = self.layer5(x, self.long_skip[0])\n",
        "        x, temp = self.layer6(x, self.long_skip[1])\n",
        "        x, temp = self.layer7(x, self.long_skip[2])\n",
        "        x, temp = self.layer8(x, None)\n",
        "\n",
        "        # Final layers to produce the segmentation map\n",
        "        x = self.conv_last1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.cat((x, self.long_skip[3]), dim=1)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv_last2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.Softmax(x)\n",
        "\n",
        "        # Clean up to save memory\n",
        "        del self.long_skip, temp\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, out_channels, stride, up=False):\n",
        "        # Helper method to create a layer of blocks\n",
        "        # Parameters:\n",
        "        #   block: The type of block (standard or bottleneck)\n",
        "        #   num_residual_blocks: Number of blocks in the layer\n",
        "        #   out_channels: Number of output channels\n",
        "        #   stride: Stride for convolutional layers\n",
        "        #   up: Flag to indicate if this is an upward (True) or downward (False) layer\n",
        "\n",
        "        identity_scale = None\n",
        "        layers = []\n",
        "\n",
        "        # Downward path construction\n",
        "        if not up:\n",
        "            # Adjust identity mapping for residual connections if needed\n",
        "            if stride != 1 or self.in_channels != out_channels*block.expansion:\n",
        "                identity_scale = mySequential(\n",
        "                    nn.Conv2d(self.in_channels, out_channels*block.expansion, kernel_size=1, stride=stride),\n",
        "                    nn.BatchNorm2d(out_channels*block.expansion)\n",
        "                )\n",
        "\n",
        "            layers.append(block(self.in_channels, out_channels, identity_scale, stride))\n",
        "            self.in_channels = out_channels*block.expansion\n",
        "\n",
        "            for i in range(num_residual_blocks - 1):\n",
        "                layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        # Upward path construction\n",
        "        else:\n",
        "            # Adjust identity mapping for residual connections in upward layers\n",
        "            if stride != 1 or self.in_channels != out_channels*block.expansion:\n",
        "                identity_scale = mySequential(\n",
        "                    nn.ConvTranspose2d(self.in_channels, out_channels*block.expansion, kernel_size=stride, stride=stride),\n",
        "                    nn.BatchNorm2d(out_channels*block.expansion)\n",
        "                )\n",
        "            # Adjust out_channels for standard block\n",
        "            out_channels = int(out_channels / block.out_multiply)\n",
        "            layers.append(block(self.in_channels, out_channels, identity_scale, stride, up=True))\n",
        "\n",
        "            # Update in_channels based on block type and expansion\n",
        "            if stride == 1 and up:\n",
        "                self.in_channels = out_channels * 2\n",
        "            elif block.expansion == 1 and up:\n",
        "                self.in_channels = out_channels * 2\n",
        "            else:\n",
        "                self.in_channels = out_channels * 4\n",
        "\n",
        "            for i in range(num_residual_blocks - 1):\n",
        "                layers.append(block(self.in_channels, out_channels, up=True))\n",
        "\n",
        "        return mySequential(*layers)\n",
        "\n",
        "# Factory functions to create UResNet models with different configurations\n",
        "def UResNet18(in_channels=3, num_classes=1000):\n",
        "    # Returns a UResNet18 model\n",
        "    return UResNet(block_standard, [2, 2, 2, 2], in_channels, num_classes)\n",
        "\n",
        "def UResNet34(in_channels=3, num_classes=1000):\n",
        "    # Returns a UResNet34 model\n",
        "    return UResNet(block_standard, [3, 4, 6, 3], in_channels, num_classes)\n",
        "\n",
        "def UResNet50(in_channels=3, num_classes=1000):\n",
        "    # Returns a UResNet50 model\n",
        "    return UResNet(block_bottleneck, [3, 4, 6, 3], in_channels, num_classes)\n",
        "\n",
        "def UResNet101(in_channels=3, num_classes=1000):\n",
        "    # Returns a UResNet101 model\n",
        "    return UResNet(block_bottleneck, [3, 4, 23, 3], in_channels, num_classes)\n",
        "\n",
        "def UResNet152(in_channels=3, num_classes=1000):\n",
        "    # Returns a UResNet152 model\n",
        "    return UResNet(block_bottleneck, [3, 8, 36, 3], in_channels, num_classes)\n",
        "\n",
        "def test():\n",
        "    # Test function to verify the model output\n",
        "    net = UResNet18()\n",
        "    x = torch.randn(2, 3, 224, 224)  # Dummy input\n",
        "    if torch.cuda.is_available():\n",
        "        y = net(x).to('cuda')\n",
        "    else:\n",
        "        y = net(x)\n",
        "    print(y.shape)  # Print the output shape for verification\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWAj3YuwDSrd"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This file is used together with the 'train.py' file to help in the training and\n",
        "testing process with util functions.\n",
        "'''\n",
        "import torch\n",
        "#from dataset import DresdenDataset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.transforms.functional as tf\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from torchmetrics import Dice\n",
        "\n",
        "\n",
        "# The next functions are functional transforms, used to apply functions in a way\n",
        "# controled by the user. So we can apply, for example, in the data image and in\n",
        "# the label image (so it is called deterministic, because we can determine the\n",
        "# same transformation to be applied in more then one image). This is the unique\n",
        "# way to apply the same transformation to more then one different image in torch\n",
        "\n",
        "class ToTensor(object):\n",
        "    '''Function to transform a ndarray in a tensor\n",
        "\n",
        "    n: int (input)\n",
        "        number of non-mask images to convert to tensor (the rest will be\n",
        "        converted without scaling to [0.0,1.0])'''\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for i, image in enumerate(images):\n",
        "            if i < self.n:\n",
        "                images[image] = tf.to_tensor(images[image])\n",
        "            else:\n",
        "                images[image] = torch.from_numpy(images[image])\n",
        "                images[image] = torch.permute(images[image], (2,0,1))\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class Rotate(object):\n",
        "    '''Function to rotate an image, the input is a dictionary\n",
        "\n",
        "    images: 'dictionary' (input)\n",
        "        dictionary with images;\n",
        "    limit: 'list'\n",
        "        a list 'int' with smaller and larger angles to rotate (e.g. [0, 90]);\n",
        "    p: 'float'\n",
        "        probability to rotate;\n",
        "\n",
        "    dictionary: 'dictionary' (output)\n",
        "        dictionary with cropped images with keys 'image0', 'image1', etc.\n",
        "    '''\n",
        "    def __init__(self,**kwargs):\n",
        "        # 'limit' is a 'list' that defines the lower and upper angular limits\n",
        "        limit = kwargs.get('limit')\n",
        "        if not limit: limit = [0, 360]\n",
        "        self.limit = limit\n",
        "        # 'p' is 'float' the probability to happen a rotate\n",
        "        p = kwargs.get('p')\n",
        "        if not p: p = 0.5\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, images):\n",
        "        if random.random() > 1-self.p:\n",
        "            angle = random.randint(self.limit[0], self.limit[1])\n",
        "            for i, image in enumerate(images):\n",
        "                images[image] = tf.rotate(images[image], angle)\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class CenterCrop(object):\n",
        "    '''Function to center crop one or multiple images\n",
        "\n",
        "    size: 'list' (input)\n",
        "        input list with size (e.g. '[400,200]');\n",
        "    images: 'dictionary' (input) (output)\n",
        "        dictionary with images.\n",
        "    '''\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for image in images:\n",
        "            images[image] = tf.center_crop(images[image], self.size)\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class Resize(object):\n",
        "    '''Function to resize one or multiple images\n",
        "\n",
        "    size: 'list' (input)\n",
        "        input list with size (e.g. '[400,200]');\n",
        "    images: 'dictionary' (input) (output)\n",
        "        dictionary with images.\n",
        "    '''\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for image in images:\n",
        "            images[image] = tf.resize(images[image], self.size)\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class FlipHorizontal(object):\n",
        "    '''Horizontally flip images randomly\n",
        "\n",
        "    p: 'float' (input)\n",
        "        probability to flip (from 0.0 to 1.0).\n",
        "    '''\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, images):\n",
        "        if random.random() > 1-self.p:\n",
        "            for image in images:\n",
        "                images[image] = tf.hflip(images[image])\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class FlipVertical(object):\n",
        "    '''Vertically flip images randomly\n",
        "\n",
        "    p: 'float' (input)\n",
        "        probability to flip (from 0.0 to 1.0).\n",
        "    '''\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, images):\n",
        "        if random.random() > 1-self.p:\n",
        "            for image in images:\n",
        "                images[image] = tf.vflip(images[image])\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class Normalize(object):\n",
        "    '''Normalizing 'n' images of a given set of images\n",
        "\n",
        "    n: int (input)\n",
        "        number of images to normalize;\n",
        "    mean: list (input)\n",
        "        mean to normalize;\n",
        "    std: list (input)\n",
        "        stadard deviation to normalize.\n",
        "    '''\n",
        "    def __init__(self, n=1, mean=0.5, std=0.5):\n",
        "        self.n = n\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for i, image in enumerate(images):\n",
        "            if i < self.n:\n",
        "                images[image] = tf.normalize(images[image], self.mean, self.std)\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "class Affine(object):\n",
        "    '''Affining images\n",
        "\n",
        "    size: list (input)\n",
        "        maximum higher and width to translate image (normally the image size);\n",
        "    scale: float (input)\n",
        "        scale to perform affine (between 0 and 1.0);\n",
        "    p: float (input)\n",
        "        probability to thange.'''\n",
        "    def __init__(self, size=[0,0], scale=0.5, p=0.5):\n",
        "        self.size = size\n",
        "        self.scale = scale\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, images):\n",
        "        if random.random() > 1-self.p:\n",
        "            angle = random.random()*self.scale*360\n",
        "            shear = random.random()*self.scale*360\n",
        "            translate = [i*random.random()*self.scale for i in self.size]\n",
        "            for image in images:\n",
        "                images[image] = tf.affine(images[image], angle=angle,\n",
        "                                         translate=translate, scale=1-self.scale,\n",
        "                                         shear=shear)\n",
        "        return images\n",
        "\n",
        "\n",
        "#%% Util Functions to be Used During Training or Testing\n",
        "\n",
        "# saving checkpoints\n",
        "def save_checkpoint(state, filename='my_checkpoint.pth.tar'):\n",
        "    print('\\n- Saving Checkpoint...')\n",
        "    torch.save(state, filename)\n",
        "\n",
        "# loading checkpoints\n",
        "def load_checkpoint(checkpoint, model, optimizer=None):\n",
        "    print('\\n- Loading Checkpoint...')\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    if optimizer:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "# getting loaders given directories and other informations\n",
        "def get_loaders(train_image_dir,\n",
        "                valid_percent,\n",
        "                test_percent,\n",
        "                batch_size,\n",
        "                image_height,\n",
        "                image_width,\n",
        "                num_workers=1,\n",
        "                pin_memory=True,\n",
        "                val_image_dir=None,\n",
        "                clip_valid=1.0,\n",
        "                clip_train=1.0):\n",
        "\n",
        "    # first, defining transformations to be applied in the train images to be loaded\n",
        "    transform_train_0 = Compose([ToTensor(n=1),\n",
        "                                 Resize(size=[image_height, image_width]),\n",
        "                                 FlipVertical(p=0.5),\n",
        "                                 FlipHorizontal(p=0.5),\n",
        "                                 # mean and std, obtained from Dresden Dataset\n",
        "                                 # for segmentation\n",
        "                                 Normalize(n=1, mean=[0.4338, 0.31936, 0.312387],\n",
        "                                           std=[0.1904, 0.15638, 0.15657])]\n",
        "                                )\n",
        "    # defining the same, but for validation and testing images (can be different)\n",
        "    transform_valid_0 = Compose([ToTensor(n=1),\n",
        "                                 Resize(size=[image_height, image_width]),\n",
        "                                 FlipVertical(p=0.5),\n",
        "                                 FlipHorizontal(p=0.5),\n",
        "                                 # defining again if validation dataset is dif.\n",
        "                                 Normalize(n=1, mean=[0.4338, 0.31936, 0.312387],\n",
        "                                           std=[0.1904, 0.15638, 0.15657])]\n",
        "                                )\n",
        "\n",
        "    # second, defining the number of transformations per directory in\n",
        "    # 'train_image_dir' defines the data augmantation (1 for no augmentation\n",
        "    # and 5 for 5 times augmentation)\n",
        "    transformations_per_dataset = [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
        "                                   5, 5, 5, 5, 5, 5]\n",
        "\n",
        "    # third, reading the dataset in a as a 'torch.utils.data.Dataset' instance.\n",
        "    # it is only for images in 'train_image_dir[0]', further we will accounts\n",
        "    # for the rest of the directories\n",
        "    train_dataset = DresdenDataset(image_dir=train_image_dir[0],\n",
        "                                  transform=transform_train_0)\n",
        "    print(\"train_dataset:\",train_dataset)\n",
        "\n",
        "    # concatenate the other directories in 'train_image_dir[:]' in a larger\n",
        "    # 'torhc.utils.data.Dataset'. after we will concatenate more for augmentat.\n",
        "    for n in range(1, len(train_image_dir)):\n",
        "        dataset_train_temp = DresdenDataset(image_dir=train_image_dir[n],\n",
        "                                           transform=transform_train_0)\n",
        "        # to use 'train_dataset' here in right, we have to define it before\n",
        "        train_dataset = torch.utils.data.ConcatDataset([train_dataset,\n",
        "                                                        dataset_train_temp])\n",
        "\n",
        "    # using part of the training data as test dataset\n",
        "    test_dataset_size = int(test_percent*len(train_dataset))\n",
        "    rest_size = int((1-test_percent)*len(train_dataset))\n",
        "    if test_dataset_size+rest_size != len(train_dataset):\n",
        "        rest_size += 1\n",
        "    (test_dataset, _) = random_split(train_dataset, [test_dataset_size, rest_size],\n",
        "                                     generator=(torch.Generator().manual_seed(40)))\n",
        "\n",
        "    # defining the validation dataset, using part of the 'train_dataset', or\n",
        "    # using a specific dataset for validation, if 'val_image_dir' is not 'None'\n",
        "    if not val_image_dir:\n",
        "        valid_dataset_size = int(valid_percent*len(train_dataset))\n",
        "        train_dataset_size = int((1-valid_percent)*len(train_dataset))\n",
        "        # adding one to train_dataset_size if 'int' operation removed it\n",
        "        if valid_dataset_size+train_dataset_size != len(train_dataset):\n",
        "            train_dataset_size += 1\n",
        "        (train_dataset, valid_dataset) = random_split(train_dataset,\n",
        "                                         [train_dataset_size, valid_dataset_size],\n",
        "                                         generator=torch.Generator().manual_seed(20))\n",
        "    else:\n",
        "        valid_dataset = DresdenDataset(image_dir=val_image_dir[0],\n",
        "                                      transform=transform_valid_0)\n",
        "        for n in range(1, len(val_image_dir)):\n",
        "            dataset_val_temp = DresdenDataset(image_dir=val_image_dir[n],\n",
        "                                             transform=transform_valid_0)\n",
        "            valid_dataset = torch.utils.data.ConcatDataset([valid_dataset,\n",
        "                                                            dataset_val_temp])\n",
        "\n",
        "    # concatenating the augmented data, in case 'transf..._per_dataset' > 1\n",
        "    for n in range(0,len(train_image_dir)):\n",
        "        for m in range(1, transformations_per_dataset[n]):\n",
        "            # first we specify the transformation (depending on the 'm' value)\n",
        "            if m < 2:\n",
        "                transformation = Compose([ToTensor(n=1),\n",
        "                                          Rotate(limit=[(m-1)*72,m*72], p=1.0),\n",
        "                                          Resize(size=[image_height, image_width]),\n",
        "                                          FlipVertical(p=0.5),\n",
        "                                          FlipHorizontal(p=0.5),\n",
        "                                          # Mean and std, obtained from the dataset\n",
        "                                          Normalize(n=1, mean=[0.4338, 0.31936, 0.312387],\n",
        "                                                    std=[0.1904, 0.15638, 0.15657])]\n",
        "                                          )\n",
        "            else:\n",
        "                transformation = Compose([ToTensor(n=1),\n",
        "                                          Affine(size=[0.5*image_height, 0.5*image_width],\n",
        "                                                 scale=0.01*(m-1), p=0.5),\n",
        "                                          Rotate(limit=[(m-1)*72,m*72], p=1.0),\n",
        "                                          Resize(size=[image_height, image_width]),\n",
        "                                          FlipVertical(p=0.5),\n",
        "                                          FlipHorizontal(p=0.5),\n",
        "                                          # Mean and std, obtained from the dataset\n",
        "                                          Normalize(n=1, mean=[0.4338, 0.31936, 0.312387],\n",
        "                                                    std=[0.1904, 0.15638, 0.15657])]\n",
        "                                          )\n",
        "            # then we apply this transformation to read the dataset as 'torch.utils.data.Dataset'\n",
        "            dataset_train_temp = DresdenDataset(image_dir=train_image_dir[n],\n",
        "                                               transform=transformation)\n",
        "            train_dataset = torch.utils.data.ConcatDataset([train_dataset, dataset_train_temp])\n",
        "\n",
        "    # splitting the dataset, to deminish if 'clip_valid'<1 for fast testing\n",
        "    if clip_train < 1:\n",
        "        print('\\n- Splitting Training Dataset ',clip_train*100,'%')\n",
        "        train_mini = int(clip_train*len(train_dataset))\n",
        "        temp_mini = int((1-clip_train)*len(train_dataset))\n",
        "        if train_mini+temp_mini != len(train_dataset):\n",
        "            temp_mini += 1\n",
        "        (train_dataset, _) = random_split(train_dataset,[train_mini, temp_mini],\n",
        "                                          generator=torch.Generator().manual_seed(40))\n",
        "    if clip_valid < 1:\n",
        "        print('\\n- Splitting Validation Dataset ',clip_valid*100,'%')\n",
        "        valid_mini = int(clip_valid*len(valid_dataset))\n",
        "        temp_mini = int((1-clip_valid)*len(valid_dataset))\n",
        "        if valid_mini+temp_mini != len(valid_dataset):\n",
        "            temp_mini += 1\n",
        "        (valid_dataset, _) = random_split(valid_dataset,[valid_mini, temp_mini],\n",
        "                                          generator=torch.Generator().manual_seed(30))\n",
        "        (test_dataset, _) = random_split(test_dataset, [valid_mini, temp_mini],\n",
        "                                         generator=torch.Generator().manual_seed(50))\n",
        "\n",
        "    # obtaining dataloader from the datasets defined above\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "\n",
        "    return train_loader, test_loader, valid_loader\n",
        "\n",
        "# functino to check accuracy\n",
        "def check_accuracy(loader, model, loss_fn, device='cuda' if torch.cuda.is_available() else 'cpu', **kwargs):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    model.eval()\n",
        "    # if title is passed, use it before 'Check acc' and 'Got an accuracy...'\n",
        "    title = kwargs.get('title')\n",
        "    if title==None: title = ''\n",
        "    else: title = title+': '\n",
        "    # using tqdm.tqdm to show a progress bar\n",
        "    loop = tqdm(loader, desc=title+'Check acc')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for dictionary in loop:\n",
        "            image, label = dictionary\n",
        "            x, y = dictionary[image], dictionary[label]\n",
        "            x, y = x.to(device=device), y.to(device=device)\n",
        "            y = y.float()\n",
        "            pred = model(x)\n",
        "            y = tf.center_crop(y, pred.shape[2:])\n",
        "            pred = (pred > 0.5).float()\n",
        "            loss = loss_fn(pred, y)\n",
        "            num_correct += (pred == y).sum()\n",
        "            num_pixels += torch.numel(pred)\n",
        "            # next is to calculate dice-score\n",
        "            pred = pred.to(device='cpu').to(torch.int32)\n",
        "            y = y.to(device='cpu').to(torch.int32)\n",
        "            dice = Dice(ignore_index=0)\n",
        "            dice_score += dice(pred, y)\n",
        "            loop.set_postfix(acc=str(round(100*num_correct.item()/int(num_pixels),4)))\n",
        "            # deliting variables\n",
        "            loss_item = loss.item()\n",
        "            del loss, pred, x, y, image, label, dictionary\n",
        "    # deliting variables\n",
        "    num_correct_item = num_correct.item()\n",
        "    num_pixels = int(num_pixels)\n",
        "    dice_score_item = dice_score.item()\n",
        "    len_loader = len(loader)\n",
        "    del num_correct, dice_score, loader, loop\n",
        "\n",
        "    print('\\n'+title+f'Got an accuracy of {round(100*num_correct_item/int(num_pixels),4)}')\n",
        "\n",
        "    print('\\n'+title+f'Dice score: {round(100*dice_score_item/len_loader,4)}'+'\\n')\n",
        "    model.train()\n",
        "    return 100*num_correct_item/num_pixels, loss_item, 100*dice_score_item/len_loader\n",
        "\n",
        "# saving images (only if the output are images)\n",
        "def save_predictions_as_imgs(loader, model, folder='saved_images',\n",
        "                             device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "                             **kwargs):\n",
        "    # If image is grayscale, if yes, we have to turn into rgb to save\n",
        "    gray = kwargs.get('gray')\n",
        "    # With model in evaluation\n",
        "    model.eval()\n",
        "    for idx, (dictionary) in enumerate(loader):\n",
        "        image, label = dictionary\n",
        "        x, y = dictionary[image], dictionary[label]\n",
        "        x = x.to(device=device)\n",
        "        y = y.to(dtype=torch.float32)\n",
        "        y = y.to(device=device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(x)\n",
        "            y = tf.center_crop(y, pred.shape[2:])\n",
        "            pred = (pred > 0.5).float()\n",
        "        # If image is grayscale, transforming to 'rgb' (utils.save_image needs)\n",
        "        if gray:\n",
        "            pred = torch.cat([pred,pred,pred],1)\n",
        "            y = y.unsqueeze(1)\n",
        "            y = torch.cat([y,y,y],1)\n",
        "            y = y.float()\n",
        "            y = tf.center_crop(y, pred.shape[2:])\n",
        "        save_image(pred, f'{folder}/pred_{idx}.png')\n",
        "        save_image(y, f'{folder}/y_{idx}.png')\n",
        "\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c9xwLZJbZ32T",
        "outputId": "8c901625-b597-4824-a570-07b3dcdae832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "train_dataset: <__main__.DresdenDataset object at 0x78babdabff40>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Loading Checkpoint...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [01:09<00:00,  5.33s/it, acc=78.7037]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 78.7037\n",
            "\n",
            "Dice score: 79.5626\n",
            "\n",
            "\n",
            "- Continue Training...\n",
            "\n",
            "\n",
            "- Loading Checkpoint...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 8:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 8: 100%|██████████| 578/578 [20:30<00:00,  2.13s/it, loss=0.342]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:18<00:00,  1.43s/it, acc=81.8654]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 81.8654\n",
            "\n",
            "Dice score: 82.4204\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:24<00:00,  1.35s/it, acc=78.9472]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 78.9472\n",
            "\n",
            "Dice score: 79.4599\n",
            "\n",
            "\n",
            "- Time taken: 117.519 min\n",
            "\n",
            "- Last Learning rate: 0.00043047 \n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 9:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 9: 100%|██████████| 578/578 [12:46<00:00,  1.33s/it, loss=0.313]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:18<00:00,  1.41s/it, acc=85.217]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 85.217\n",
            "\n",
            "Dice score: 85.7663\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:24<00:00,  1.38s/it, acc=80.1321]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 80.1321\n",
            "\n",
            "Dice score: 80.6962\n",
            "\n",
            "\n",
            "- Time taken: 131.066 min\n",
            "\n",
            "- Last Learning rate: 0.00038742 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 10:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 10: 100%|██████████| 578/578 [12:43<00:00,  1.32s/it, loss=0.313]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:20<00:00,  1.58s/it, acc=80.6496]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 80.6496\n",
            "\n",
            "Dice score: 81.3147\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:23<00:00,  1.31s/it, acc=78.5461]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 78.5461\n",
            "\n",
            "Dice score: 78.7411\n",
            "\n",
            "\n",
            "- Time taken: 144.583 min\n",
            "\n",
            "- Last Learning rate: 0.00034868 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 11:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 11: 100%|██████████| 578/578 [12:44<00:00,  1.32s/it, loss=0.361]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:20<00:00,  1.56s/it, acc=81.66]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 81.66\n",
            "\n",
            "Dice score: 81.7954\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:25<00:00,  1.43s/it, acc=75.1744]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 75.1744\n",
            "\n",
            "Dice score: 75.3911\n",
            "\n",
            "\n",
            "- Time taken: 158.133 min\n",
            "\n",
            "- Last Learning rate: 0.00031381 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 12:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 12: 100%|██████████| 578/578 [12:38<00:00,  1.31s/it, loss=0.29]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:17<00:00,  1.35s/it, acc=82.4854]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 82.4854\n",
            "\n",
            "Dice score: 83.098\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:22<00:00,  1.27s/it, acc=79.6688]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 79.6688\n",
            "\n",
            "Dice score: 80.1422\n",
            "\n",
            "\n",
            "- Time taken: 171.488 min\n",
            "\n",
            "- Last Learning rate: 0.00028243 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 13:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 13: 100%|██████████| 578/578 [12:50<00:00,  1.33s/it, loss=0.334]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:18<00:00,  1.44s/it, acc=83.4602]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 83.4602\n",
            "\n",
            "Dice score: 83.948\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:23<00:00,  1.31s/it, acc=79.4539]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 79.4539\n",
            "\n",
            "Dice score: 79.5696\n",
            "\n",
            "\n",
            "- Time taken: 185.095 min\n",
            "\n",
            "- Last Learning rate: 0.00025419 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 14:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 14: 100%|██████████| 578/578 [12:39<00:00,  1.31s/it, loss=0.317]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:16<00:00,  1.27s/it, acc=79.967]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 79.967\n",
            "\n",
            "Dice score: 80.5039\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:23<00:00,  1.30s/it, acc=78.0893]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 78.0893\n",
            "\n",
            "Dice score: 78.6845\n",
            "\n",
            "\n",
            "- Time taken: 198.452 min\n",
            "\n",
            "- Last Learning rate: 0.00022877 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 15:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 15: 100%|██████████| 578/578 [12:49<00:00,  1.33s/it, loss=0.319]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:17<00:00,  1.33s/it, acc=83.6484]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 83.6484\n",
            "\n",
            "Dice score: 84.2932\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:21<00:00,  1.18s/it, acc=80.3957]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 80.3957\n",
            "\n",
            "Dice score: 80.9761\n",
            "\n",
            "\n",
            "- Time taken: 211.985 min\n",
            "\n",
            "- Last Learning rate: 0.00020589 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 16:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 16: 100%|██████████| 578/578 [12:59<00:00,  1.35s/it, loss=0.284]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:18<00:00,  1.40s/it, acc=83.4254]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 83.4254\n",
            "\n",
            "Dice score: 84.0319\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:25<00:00,  1.39s/it, acc=81.3694]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 81.3694\n",
            "\n",
            "Dice score: 81.9751\n",
            "\n",
            "\n",
            "- Time taken: 225.745 min\n",
            "\n",
            "- Last Learning rate: 0.0001853 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 17:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 17: 100%|██████████| 578/578 [12:53<00:00,  1.34s/it, loss=0.289]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:18<00:00,  1.45s/it, acc=82.749]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 82.749\n",
            "\n",
            "Dice score: 83.2806\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:23<00:00,  1.33s/it, acc=82.0431]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 82.0431\n",
            "\n",
            "Dice score: 82.5918\n",
            "\n",
            "\n",
            "- Time taken: 239.394 min\n",
            "\n",
            "- Last Learning rate: 0.00016677 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 18:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 18: 100%|██████████| 578/578 [12:55<00:00,  1.34s/it, loss=0.264]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, acc=82.3093]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 82.3093\n",
            "\n",
            "Dice score: 82.9313\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:27<00:00,  1.50s/it, acc=78.4338]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 78.4338\n",
            "\n",
            "Dice score: 79.077\n",
            "\n",
            "\n",
            "- Time taken: 253.151 min\n",
            "\n",
            "- Last Learning rate: 0.00015009 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 19:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 19: 100%|██████████| 578/578 [12:58<00:00,  1.35s/it, loss=0.336]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:22<00:00,  1.71s/it, acc=83.6308]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 83.6308\n",
            "\n",
            "Dice score: 84.2486\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:23<00:00,  1.30s/it, acc=80.1716]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 80.1716\n",
            "\n",
            "Dice score: 80.7613\n",
            "\n",
            "\n",
            "- Time taken: 266.924 min\n",
            "\n",
            "- Last Learning rate: 0.00013509 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 20:   0%|          | 0/578 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 20: 100%|██████████| 578/578 [12:59<00:00,  1.35s/it, loss=0.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Saving Checkpoint...\n",
            "\n",
            "Validating:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 13/13 [00:18<00:00,  1.41s/it, acc=79.5458]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 79.5458\n",
            "\n",
            "Dice score: 80.3123\n",
            "\n",
            "Testing:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCheck acc:   0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Check acc: 100%|██████████| 18/18 [00:22<00:00,  1.28s/it, acc=78.8385]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Got an accuracy of 78.8385\n",
            "\n",
            "Dice score: 79.3413\n",
            "\n",
            "\n",
            "- Time taken: 280.651 min\n",
            "\n",
            "- Last Learning rate: 0.00012158 \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Algorithm to Train, Save and Continue Training of Segmentation Models\n",
        "\n",
        "This is a training algorithm for segmentation tasks, that can be used to\n",
        "perform five tasks (training, saving, and testing models, but alose continue a\n",
        "training and saving image examples comparing prediction and label) in a diverse\n",
        "range of models. Next we will see which are the specific models applied using\n",
        "these algorithms, but we can adapt them to train a range of other segmenta-\n",
        "tion models, with just small changes (for classification models, please refers\n",
        "to the algorithms in the folder 'Classification\\train.py').\n",
        "\n",
        "This program runs together with the files 'utils.py', 'model.py' and 'dataset.\n",
        "py' to perform the training of the UResNet models (from 18 to 152 layers, as\n",
        "specified at 'model.py'), which are based in the encoder-decoder architecture,\n",
        "(see torch documentation for more information at\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial).\n",
        "\n",
        "Standard Training: To train a model from zero (or from the first epoch), just\n",
        "define the hyperparameters, as needed, and choose 'continue_training = False',\n",
        "and 'last_epoch = 0' (parameter only used for continue a training). In order to\n",
        "save your model, change 'save_model' to True, and to save images resultesd from\n",
        "the segmentaiton (from the validation dataset), in the folder 'saved_images'\n",
        "inside the 'root_folder', change 'save_images' to True. Variables 'test_model'\n",
        "and 'load_model' are for other popouses (see options below), and can set to\n",
        "False during the first training.\n",
        "\n",
        "Continue a Training: set 'continue_training = True' in the hyperparameters to\n",
        "continue a training, also setting 'last_epoch' with the number of epochs\n",
        "already trained (e.g. if you trained 10 epochs, and want to continue, set\n",
        "'last_epoch = 10'. Also the name of the pre-trained model has to exactly match\n",
        "chekpoint_dir in the 'root_folder' directory, and the 'csv' file with\n",
        "previous results, 'dictionary.csv', also has to be in 'root_folder'. The varia-\n",
        "ble 'laod_model' does not need to be 'True' (it is just to test, see below).\n",
        "\n",
        "Testing models: If you only want to test one or more models, just set\n",
        "'test_models = True', and specify the directory where the models to be tested\n",
        "are as a string in the variable 'test_models_dir'. If other options are also\n",
        "chosen, the test will take place in the and, after the other options finish.\n",
        "\n",
        "Loading and Testing One Model: if you want to test a model before continue a\n",
        "training, or just wants to load and test one model, choose 'load_model = True'.\n",
        "This will test the model chekpoint_dir stored in the 'root_folder'.\n",
        "\n",
        "\n",
        "Find more on the GitHub Repository:\n",
        "https://github.com/MarlonGarcia/attacking-white-blood-cells\n",
        "\n",
        "\n",
        "@author: THALES PIMENTEL ZUANAZZI\n",
        "@instit: UNESP\n",
        "\n",
        "code built on previus work from:\n",
        "\n",
        "@author: Marlon Rodrigues Garcia\n",
        "@instit: University of São Paulo\n",
        "\n",
        "\n",
        "\n",
        "  A B C D\n",
        "1 1 1 1 1\n",
        "2 1 2 2 3\n",
        "3 1 3 3 2\n",
        "4 2 1 2 2\n",
        "5 2 2 3 1\n",
        "6 2 3 1 3\n",
        "7 3 1 3 3\n",
        "8 3 2 1 2\n",
        "9 3 3 2 1\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "B = learning_rate = 5e-4 1e-3 1e-4\n",
        "A = batch_size = 8 6 12\n",
        "C = model = UResNet34(in_channels=3, num_classes=2).to(device) UResNet18(in_channels=3, num_classes=2).to(device) UResNet50(in_channels=3, num_classes=2).to(device)\n",
        "D = loss = nn.CrossEntropyLoss()  CustomLoss()   nn.L1Loss()\n",
        "\"\"\"\n",
        "\n",
        "### Program  Header\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# running on Colabs, mounting drive\n",
        "run_on_colabs = True\n",
        "# Importing Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# To import add current folder to path (import py files):\n",
        "import sys\n",
        "root_folder = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal'\n",
        "#              /content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal\n",
        "sys.path.append(root_folder)\n",
        "test_models_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal'\n",
        "chekpoint_dir = 'my_checkpoint10.pth.tar'\n",
        "\n",
        "# defining where to save results\n",
        "save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal'\n",
        "import os\n",
        "os.chdir(root_folder)\n",
        "\n",
        "#from model import *\n",
        "#from utils import *\n",
        "\n",
        "# defining the paths to datasets\n",
        "train_image_dir = ['/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/01',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/02',\n",
        "                      #  '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/03',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/04',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/05',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/abdominal_wall/06',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/abdominal_wall/07',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/pancreas/08',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/abdominal_wall/09',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/abdominal_wall/10',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/11',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/12',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/13',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/abdominal_wall/14',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/15',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/abdominal_wall/16',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/abdominal_wall/17',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/18',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/abdominal_wall/19',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/20',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/21',\n",
        "                      #  '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/22',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/abdominal_wall/23',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/24',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/25',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/26',\n",
        "                       #'/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/pancreas/27',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/28',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/29',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/30',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/31'\n",
        "                       ]\n",
        "\n",
        "val_image_dir = ['/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/03',\n",
        "                       '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Datasets/DSAD/liver/22'\n",
        "                       ]\n",
        "\n",
        "\n",
        "#%% Training Function\n",
        "\n",
        "# defining the training function\n",
        "def train_fn(loader, model, optimizer, loss_fn, scaler, schedule, epoch, last_lr):\n",
        "    loop = tqdm(loader, desc='Epoch '+str(epoch+1))\n",
        "\n",
        "    for batch_idx, (dictionary) in enumerate(loop):\n",
        "        image, label = dictionary\n",
        "        x, y = dictionary[image], dictionary[label]\n",
        "        x, y = x.to(device=device), y.to(device=device)\n",
        "        y = y.float()\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast() if torch.cuda.is_available() else torch.autocast('cpu'):\n",
        "            pred = model(x)\n",
        "            # cropping 'pred' for when the model changes the image dimensions\n",
        "            y = tf.center_crop(y, pred.shape[2:])\n",
        "            # calculating loss\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        if device == 'cuda':\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scale = scaler.get_scale()\n",
        "            scaler.update()\n",
        "        # if device='cpu', we cannot use 'scaler=torch.cuda.amp.GradScaler()':\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        # freeing space by deliting variables\n",
        "        loss_item = loss.item()\n",
        "        del loss, pred, y, x, image, label, dictionary\n",
        "        # updating tgdm loop\n",
        "        loop.set_postfix(loss=loss_item)\n",
        "    # deliting loader and loop\n",
        "    del loader, loop\n",
        "    # scheduling the learning rate and saving its last value\n",
        "    if scaler:\n",
        "        if scale >= scaler.get_scale():\n",
        "            schedule.step()\n",
        "            last_lr = schedule.get_last_lr()\n",
        "    else:\n",
        "        schedule.step()\n",
        "        last_lr = schedule.get_last_lr()\n",
        "\n",
        "    return loss_item, last_lr\n",
        "\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, alpha=1.0, beta=1.0):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.alpha = alpha  # Weight for true positive loss\n",
        "        self.beta = beta   # Weight for false negative loss\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Assuming predictions and targets are binary (0 or 1)\n",
        "        # Calculate true positives\n",
        "        true_positives = (predictions * targets)\n",
        "\n",
        "        # Calculate false negatives\n",
        "        false_negatives = ((1 - predictions) * targets)\n",
        "\n",
        "        # Compute loss based on true positives and false negatives\n",
        "        true_positive_loss = torch.mean((true_positives - targets) ** 2)\n",
        "        false_negative_loss = torch.mean((false_negatives) ** 2)\n",
        "\n",
        "        # Total loss with weighted components\n",
        "        loss = (self.alpha * true_positive_loss) + (self.beta * false_negative_loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "#%% Defining The main() Function\n",
        "model1 = UResNet34(in_channels=3, num_classes=2).to('cuda')\n",
        "loss1 = CustomLoss()\n",
        "def main():\n",
        "    model = model1\n",
        "    loss_fn = loss1\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    schedule = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "    # loading dataLoaders\n",
        "    train_loader, test_loader, valid_loader = get_loaders(\n",
        "        train_image_dir=train_image_dir,\n",
        "        valid_percent=valid_percent,\n",
        "        test_percent=test_percent,\n",
        "        batch_size=batch_size,\n",
        "        image_height=image_height,\n",
        "        image_width=image_width,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        val_image_dir=val_image_dir,\n",
        "        clip_valid=clip_valid,\n",
        "        clip_train=clip_train\n",
        "    )\n",
        "\n",
        "    # if this program is just to load and test a model, next it loads a model\n",
        "    if load_model:\n",
        "        # loading checkpoint\n",
        "        os.chdir(root_folder)\n",
        "        if device == 'cuda':\n",
        "            load_checkpoint(torch.load(chekpoint_dir), model)\n",
        "        # if 'cpu', we need to pass 'map_location'\n",
        "        else:\n",
        "            load_checkpoint(torch.load(chekpoint_dir,\n",
        "                                       map_location=torch.device('cpu')), model)\n",
        "        check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "\n",
        "    if not load_model or continue_training:\n",
        "        # changing folder to save dictionary\n",
        "        os.chdir(save_results_dir)\n",
        "        # if 'continue_training==True', we load the model and continue training\n",
        "        if continue_training:\n",
        "            print('\\n- Continue Training...\\n')\n",
        "            start = time.time()\n",
        "            if device == 'cuda':\n",
        "                load_checkpoint(torch.load(chekpoint_dir), model,\n",
        "                                optimizer=optimizer)\n",
        "            else:\n",
        "                load_checkpoint(torch.load(chekpoint_dir,\n",
        "                                           map_location=torch.device('cpu')),\n",
        "                                           model, optimizer=optimizer)\n",
        "            # reading the csv 'dictionary.csv' as a dictionary\n",
        "            df = pd.read_csv('dictionary.csv')\n",
        "            temp = df.to_dict('split')\n",
        "            temp = temp['data']\n",
        "            dictionary = {'acc-valid':[], 'acc-test':[], 'loss':[], 'dice score-valid':[], 'dice score-test':[], 'time taken':[]}\n",
        "            for acc_valid, acc_test, loss, dice_score_valid, dice_score_test, time_item in temp:\n",
        "                dictionary['acc-valid'].append(acc_valid)\n",
        "                dictionary['acc-test'].append(acc_test)\n",
        "                dictionary['loss'].append(loss)\n",
        "                dictionary['dice score-valid'].append(dice_score_valid)\n",
        "                dictionary['dice score-test'].append(dice_score_test)\n",
        "                dictionary['time taken'].append(time_item)\n",
        "            # adding a last time to continue conting from here\n",
        "            last_time = time_item\n",
        "        # if it is the first epoch\n",
        "        elif not continue_training:\n",
        "            print('\\n- Start Training...\\n')\n",
        "            start = time.time()\n",
        "            # opening a 'loss' and 'acc' list, to save the data\n",
        "            dictionary = {'acc-valid':[], 'acc-test':[], 'loss':[], 'dice score-valid':[], 'dice score-test':[], 'time taken':[]}\n",
        "            acc_item_valid, loss_item, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device, title='Validating')\n",
        "            acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device, title='Testing')\n",
        "            print('\\n')\n",
        "            dictionary['acc-valid'].append(acc_item_valid)\n",
        "            dictionary['acc-test'].append(acc_item_test)\n",
        "            dictionary['loss'].append(loss_item)\n",
        "            dictionary['dice score-valid'].append(dice_score_valid)\n",
        "            dictionary['dice score-test'].append(dice_score_test)\n",
        "            # we added last_time here to sum it to the 'time taken' in the\n",
        "            # dictionary. it is done because if training is continued, we can\n",
        "            # sum the actual 'last_time' taken in previous training.\n",
        "            last_time = (time.time()-start)/60\n",
        "            dictionary['time taken'].append(last_time)\n",
        "\n",
        "        # with 'cpu' we can't use 'torch.cuda.amp.GradScaler()'\n",
        "        if device == 'cuda':\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "        else:\n",
        "            scaler = None\n",
        "        # to use 'last_lr' in 'train_fn', we have to define it first\n",
        "        last_lr = schedule.get_last_lr()\n",
        "        # begining image printing\n",
        "        fig, ax = plt.subplots()\n",
        "        # Criating a new start time (we have to sum this to 'last_time')\n",
        "        start = time.time()\n",
        "\n",
        "        # running epochs\n",
        "        for epoch in range(last_epoch, num_epochs):\n",
        "            # calling training function\n",
        "            loss_item, last_lr = train_fn(train_loader, model, optimizer,\n",
        "                                          loss_fn, scaler, schedule, epoch,\n",
        "                                          last_lr)\n",
        "            # appending resulted loss from training\n",
        "            dictionary['loss'].append(loss_item)\n",
        "            # saveing model\n",
        "            if save_model and epoch >= start_save -1:\n",
        "                # changing folder to save dictionary\n",
        "                os.chdir(save_results_dir)\n",
        "                checkpoint = {\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                }\n",
        "                save_checkpoint(checkpoint, filename='my_checkpoint'+str(epoch+1)+'.pth.tar')\n",
        "            # check accuracy\n",
        "            print('\\nValidating:')\n",
        "            acc_item_valid, _, dice_score_valid = check_accuracy(valid_loader, model, loss_fn, device=device)\n",
        "            print('Testing:')\n",
        "            acc_item_test, _, dice_score_test = check_accuracy(test_loader, model, loss_fn, device=device)\n",
        "            stop = time.time()\n",
        "            dictionary['acc-valid'].append(acc_item_valid)\n",
        "            dictionary['acc-test'].append(acc_item_test)\n",
        "            dictionary['dice score-valid'].append(dice_score_valid)\n",
        "            dictionary['dice score-test'].append(dice_score_test)\n",
        "            dictionary['time taken'].append((stop-start)/60+last_time)\n",
        "            # saving some image examples to specified folder\n",
        "            if save_images:\n",
        "                # criating directory, if it does not exist\n",
        "                os.chdir(root_folder)\n",
        "                try: os.mkdir('saved_images')\n",
        "                except: pass\n",
        "                save_predictions_as_imgs(\n",
        "                    valid_loader, model, folder=os.path.join(root_folder,'saved_images'),\n",
        "                    device=device\n",
        "                )\n",
        "            # saving dictionary to a csv file\n",
        "            if save_model:\n",
        "                # changing folder to save dictionary\n",
        "                os.chdir(save_results_dir)\n",
        "                df = pd.DataFrame(dictionary, columns = ['acc-valid', 'acc-test',\n",
        "                                                         'loss', 'dice score-valid',\n",
        "                                                         'dice score-test', 'time taken'])\n",
        "                df.to_csv('dictionary.csv', index = False)\n",
        "\n",
        "            print('\\n- Time taken:',round((stop-start)/60+last_time,3),'min')\n",
        "            print('\\n- Last Learning rate:', round(last_lr[0],8),'\\n\\n')\n",
        "            # deleting variables for freeing space\n",
        "            del dice_score_test, dice_score_valid, acc_item_test, acc_item_valid, loss_item, stop\n",
        "            try: del checkpoint\n",
        "            except: pass\n",
        "\n",
        "            # continue image printing\n",
        "            if epoch == last_epoch:\n",
        "                ax.plot(np.asarray(dictionary['acc-valid']), 'C1', label ='accuracy-validation')\n",
        "                ax.plot(np.asarray(dictionary['acc-test']), 'C2', label ='accuracy-test')\n",
        "                ax.plot(np.asarray(dictionary['dice score-valid']), 'C4', label = 'dice score-validation')\n",
        "                ax.plot(np.asarray(dictionary['dice score-test']), 'C5', label = 'dice score-test')\n",
        "                ax.plot(np.asarray(dictionary['loss']), 'C3', label = 'loss')\n",
        "                plt.legend()\n",
        "                ax.set_xlabel('Epochs')\n",
        "                ax.set_ylabel('Accuracy, Loss, and Dice score')\n",
        "                plt.pause(0.5)\n",
        "            else:\n",
        "                ax.plot(np.asarray(dictionary['acc-valid']), 'C1')\n",
        "                ax.plot(np.asarray(dictionary['acc-test']), 'C2')\n",
        "                ax.plot(np.asarray(dictionary['dice score-valid']), 'C4')\n",
        "                ax.plot(np.asarray(dictionary['dice score-test']), 'C5')\n",
        "                ax.plot(np.asarray(dictionary['loss']), 'C3')\n",
        "            plt.show()\n",
        "            plt.pause(0.5)\n",
        "\n",
        "#%% Defining Parameters and Path\n",
        "\n",
        "# defining hyperparameters\n",
        "learning_rate = 5e-4    # learning rate\n",
        "device = 'cuda' #if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 8          # batch size\n",
        "num_epochs = 20         # number of epochs\n",
        "num_workers = 3         # number of workers (smaller or = n° processing units)\n",
        "clip_train = 1.00       # percentage to clip the train dataset (for tests)\n",
        "clip_valid = 1.00       # percentage to clip the valid dataset (for tests)\n",
        "valid_percent = 0.15    # use a percent of train dataset as validation dataset\n",
        "test_percent = 0.15     # a percent from training dataset (but do not excluded)\n",
        "start_save = 0          # epoch to start saving\n",
        "image_height = 512      # height to crop the image\n",
        "image_width = 640       # width to crop the image\n",
        "pin_memory = True\n",
        "load_model = False      # 'true' to load a model and test it, or use it\n",
        "save_model = True       # 'true' to save model trained after epoches\n",
        "continue_training = False # 'true' to load and continue training a model\n",
        "save_images = False      # saving example from predicted and original\n",
        "test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "last_epoch = 0\n",
        "         # when 'continue_training', it has to be the last epoch\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  #serão 9 testes, se parar no meio do caminha terá ue ver como resolver\n",
        "\n",
        "    #primeiro\n",
        "    learning_rate = 5e-4    # learning rate\n",
        "    batch_size = 8          # batch size\n",
        "    model1 = UResNet34(in_channels=3, num_classes=2).to(device)\n",
        "    loss1 = nn.CrossEntropyLoss()  #CustomLoss()\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_1'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_1'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_1'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_1/my_checkpoint7.pth.tar'\n",
        "    load_model = False      # 'true' to load a model and test it, or use it\n",
        "    save_model = True       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 0\n",
        "    main()\n",
        "\n",
        "    #segundo\n",
        "    device = 'cuda'\n",
        "    batch_size = 8 # 6 12\n",
        "    learning_rate =1e-3 #5e-4 1e-3 1e-4\n",
        "    loss1 = CustomLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet50(in_channels=3, num_classes=2).to('cuda') #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder =      '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_2'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir =  '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_2'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_2/my_checkpoint14.pth.tar'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_2'\n",
        "    last_epoch = 0\n",
        "    load_model = False      # 'true' to load a model and test it, or use it\n",
        "    save_model = True       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "    main()\n",
        "\n",
        "    # terceiro\n",
        "    batch_size = 8 # 6 12\n",
        "    learning_rate =1e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.L1Loss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet18(in_channels=3, num_classes=2).to('cuda') #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_3'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_3'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_3'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_3/my_checkpoint14.pth.tar'\n",
        "    last_epoch = 0\n",
        "    load_model = False      # 'true' to load a model and test it, or use it\n",
        "    save_model = True       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "    main()\n",
        "\n",
        "    # quarto\n",
        "    batch_size = 6 #8 6 12\n",
        "    learning_rate =5e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = CustomLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet18(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_4'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_4'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_4'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_4/my_checkpoint18.pth.tar'\n",
        "    load_model = False      # 'true' to load a model and test it, or use it\n",
        "    save_model = True       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 0\n",
        "    main()\n",
        "\n",
        "    # quinto\n",
        "    batch_size = 6 #8 6 12\n",
        "    learning_rate = 1e-3 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.L1Loss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet34(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_5'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_5'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_5'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_5/my_checkpoint12.pth.tar'\n",
        "    load_model = False      # 'true' to load a model and test it, or use it\n",
        "    save_model = True       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 0\n",
        "    main()\n",
        "\n",
        "    # sexto\n",
        "    batch_size = 6 #8 6 12\n",
        "    learning_rate = 1e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.CrossEntropyLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet50(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_6'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir =  '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_6'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_6'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_6/my_checkpoint19.pth.tar'\n",
        "    load_model = False      # 'true' to load a model and test it, or use it\n",
        "    save_model = True       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 0\n",
        "    main()\n",
        "\n",
        "    # setimo\n",
        "    batch_size = 12 #8 6 12\n",
        "    learning_rate = 5e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.L1Loss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet50(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_7'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_7'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_7'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_7/my_checkpoint11.pth.tar'\n",
        "    load_model = False      # 'true' to load a model and test it, or use it\n",
        "    save_model = True       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 0\n",
        "    main()\n",
        "\n",
        "    #oitavo\n",
        "    batch_size = 12 #8 6 12\n",
        "    learning_rate = 1e-3 #5e-4 1e-3 1e-4\n",
        "    loss1 = nn.CrossEntropyLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet18(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_8'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_8'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_8'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_8/my_checkpoint17.pth.tar'\n",
        "    load_model = False      # 'true' to load a model and test it, or use it\n",
        "    save_model = True       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 0\n",
        "    main()\n",
        "\n",
        "    #nono\n",
        "    batch_size = 12 #8 6 12\n",
        "    learning_rate = 1e-4 #5e-4 1e-3 1e-4\n",
        "    loss1 = CustomLoss()  #nn.CrossEntropyLoss() CustomLoss()   nn.L1Loss()\n",
        "    model1 = UResNet34(in_channels=3, num_classes=2).to(device) #34 18 50\n",
        "    #acima os 4 parametros editados\n",
        "    root_folder = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_9'\n",
        "    sys.path.append(root_folder)\n",
        "    test_models_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_9'\n",
        "    save_results_dir = '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_9'\n",
        "    chekpoint_dir =    '/content/gdrive/Shareddrives/Lab. of Biomedical Optics (LBO)/Trabalhos Desenvolvidos/Thales Pimentel Zuanazzi/Segmentação/teste_ortogonal/teste_9/my_checkpoint12.pth.tar'\n",
        "    load_model = False      # 'true' to load a model and test it, or use it\n",
        "    save_model = True       # 'true' to save model trained after epoches\n",
        "    continue_training = False # 'true' to load and continue training a model\n",
        "    save_images = False      # saving example from predicted and original\n",
        "    test_models = False     # true: test all the models saved in 'save_results_dir'\n",
        "    last_epoch = 0\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
